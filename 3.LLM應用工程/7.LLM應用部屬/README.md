## LLM 應用部署

### 7.1 原型開發：Gradio、Hugging Face Spaces 快速上線展示  
### 7.2 生產部署：Serverless(Lambda) vs. 自建GPU叢集(AWS, GCP, Azure)  
### 7.3 邊緣部署：在手機、瀏覽器與IoT環境中運行 LLM (MLC LLM)  
### 7.4 實作示例：
- (程式碼) 使用 Gradio 部署簡單的互動介面並分享  
- (程式碼) 使用 AWS EC2 + GPU + vLLM 部署一個可擴展的 LLM API