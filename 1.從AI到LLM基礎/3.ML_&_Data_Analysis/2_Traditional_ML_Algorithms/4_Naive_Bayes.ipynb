{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive_Bayes.ipynb\n",
    "\n",
    "本 Notebook 將詳細介紹樸素貝葉斯 (Naive Bayes) 分類器，包括：\n",
    "\n",
    "1. 貝葉斯定理基礎與 Naive Bayes 概念\n",
    "2. Zero-Frequency 問題與平滑技術（如拉普拉斯平滑）\n",
    "3. 高斯樸素貝葉斯 (GaussianNB)\n",
    "4. 多項式樸素貝葉斯 (MultinomialNB)\n",
    "5. 伯努利樸素貝葉斯 (BernoulliNB)\n",
    "6. 互補樸素貝葉斯 (ComplementNB)\n",
    "7. 實際應用案例（Iris 資料集、20 Newsgroups 文本分類、二元特徵合成資料）\n",
    "8. Pipeline、Cross-Validation、模型選擇與實務建議\n",
    "\n",
    "樸素貝葉斯分類器基於貝葉斯定理與特徵條件獨立假設，雖然假設強烈但實務中仍能取得不錯成效，特別在文本分類中表現良好，且計算速度快、對小資料集友好。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "from sklearn.datasets import load_iris, fetch_20newsgroups, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 貝葉斯定理基礎\n",
    "\n",
    "**貝葉斯定理**：\n",
    "\n",
    "$$ P(y|x) = \\frac{P(x|y)P(y)}{P(x)} $$\n",
    "\n",
    "其中：\n",
    "- $P(y|x)$：後驗機率 (posterior)，在給定 x 下 y 的機率。\n",
    "- $P(x|y)$：似然 (likelihood)，在 y 下觀察到 x 的機率。\n",
    "- $P(y)$：先驗機率 (prior)，不考慮 x 時，y 的機率。\n",
    "- $P(x)$：證據 (evidence)，觀察到 x 的整體機率。\n",
    "\n",
    "**樸素貝葉斯假設**：特徵間條件獨立。\n",
    "\n",
    "$ P(x_1, x_2, ..., x_n | y) = \\prod_{i=1}^{n} P(x_i|y) $\n",
    "\n",
    "最終決策：\n",
    "\n",
    "$ \\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n}P(x_i|y) $\n",
    "\n",
    "**優點**：\n",
    "- 訓練與預測速度快。\n",
    "- 對小樣本表現佳。\n",
    "- 對高維資料仍可行。\n",
    "\n",
    "**缺點**：\n",
    "- 特徵獨立假設在現實常不成立。\n",
    "- Zero-Frequency 問題：若某類別特徵組合未出現在訓練集中，機率估計會為0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 簡單示例 (bayes_example)\n",
    "透過一個簡單的醫學測試案例來示範貝葉斯定理計算後驗機率。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def bayes_example():\n",
    "    # 假設我們有以下數據：\n",
    "    # P(cancer) = 0.01  患癌症的機率\n",
    "    # P(positive|cancer) = 0.9 患癌症且測試陽性的機率\n",
    "    # P(positive|no cancer) = 0.2 未患癌症但測試陽性的機率\n",
    "\n",
    "    P_cancer = 0.01\n",
    "    P_positive_given_cancer = 0.9\n",
    "    P_positive_given_no_cancer = 0.2\n",
    "\n",
    "    # P(positive) = P(positive|cancer)*P(cancer) + P(positive|no_cancer)*P(no_cancer)\n",
    "    P_positive = P_positive_given_cancer * P_cancer + P_positive_given_no_cancer * (1 - P_cancer)\n",
    "\n",
    "    # P(cancer|positive) = [P(positive|cancer)*P(cancer)] / P(positive)\n",
    "    P_cancer_given_positive = (P_positive_given_cancer * P_cancer) / P_positive\n",
    "\n",
    "    print(\"檢測陽性時患癌症的機率：{:.2%}\".format(P_cancer_given_positive))\n",
    "\n",
    "bayes_example()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Zero-Frequency 問題與平滑\n",
    "\n",
    "Zero-Frequency 問題：如果訓練集中某特徵在某類別下從未出現，則該特徵與類別組合的條件機率估計為0，會導致整體後驗機率為0。\n",
    "\n",
    "**解決方法**：拉普拉斯平滑 (Laplace smoothing) 或加法平滑 (Additive smoothing)，在計數中加上常數，以避免零計數。MultinomialNB、BernoulliNB中可透過 `alpha` 參數進行平滑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GaussianNB 範例 (Iris 資料集)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 使用 Iris 資料集示範 GaussianNB\n",
    "iris = load_iris()\n",
    "X_i = iris.data\n",
    "y_i = iris.target\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X_i, y_i, test_size=0.2, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_i, y_train_i)\n",
    "y_pred_i = gnb.predict(X_test_i)\n",
    "acc_i = accuracy_score(y_test_i, y_pred_i)\n",
    "print(\"GaussianNB (Iris):\")\n",
    "print(f\"Accuracy: {acc_i:.4f}\")\n",
    "print(classification_report(y_test_i, y_pred_i, target_names=iris.target_names))\n",
    "\n",
    "# 混淆矩陣\n",
    "cm_i = confusion_matrix(y_test_i, y_pred_i)\n",
    "sns.heatmap(cm_i, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (GaussianNB)')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MultinomialNB 範例 (文本分類)\n",
    "\n",
    "使用 20 Newsgroups 部分類別示範多項式樸素貝葉斯，用 CountVectorizer 將文本轉換為詞頻特徵。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "X_train_t = vec.fit_transform(newsgroups_train.data)\n",
    "X_test_t = vec.transform(newsgroups_test.data)\n",
    "y_train_t = newsgroups_train.target\n",
    "y_test_t = newsgroups_test.target\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_t, y_train_t)\n",
    "y_pred_t = mnb.predict(X_test_t)\n",
    "acc_t = accuracy_score(y_test_t, y_pred_t)\n",
    "print(\"MultinomialNB (20 Newsgroups):\")\n",
    "print(f\"Accuracy: {acc_t:.4f}\")\n",
    "print(classification_report(y_test_t, y_pred_t, target_names=newsgroups_train.target_names))\n",
    "\n",
    "cm_t = confusion_matrix(y_test_t, y_pred_t)\n",
    "sns.heatmap(cm_t, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (MultinomialNB)')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }, 
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BernoulliNB 範例\n",
    "\n",
    "BernoulliNB 適用二元特徵（詞有無），在文本分類中可使用 `binary=True` 參數產生二元特徵。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bnb = BernoulliNB()\n",
    "vec_bin = CountVectorizer(binary=True, stop_words='english')\n",
    "X_train_bi = vec_bin.fit_transform(newsgroups_train.data)\n",
    "X_test_bi = vec_bin.transform(newsgroups_test.data)\n",
    "bnb.fit(X_train_bi, y_train_t)\n",
    "y_pred_bi = bnb.predict(X_test_bi)\n",
    "acc_bi = accuracy_score(y_test_t, y_pred_bi)\n",
    "print(\"BernoulliNB (20 Newsgroups):\")\n",
    "print(f\"Accuracy: {acc_bi:.4f}\")\n",
    "print(classification_report(y_test_t, y_pred_bi, target_names=newsgroups_train.target_names))\n",
    "\n",
    "cm_bi = confusion_matrix(y_test_t, y_pred_bi)\n",
    "sns.heatmap(cm_bi, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (BernoulliNB)')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }, 
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ComplementNB 範例\n",
    "\n",
    "ComplementNB 是 MultinomialNB 的變體，對不平衡數據更穩定。\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train_t, y_train_t)\n",
    "y_pred_c = cnb.predict(X_test_t)\n",
    "acc_c = accuracy_score(y_test_t, y_pred_c)\n",
    "print(\"ComplementNB (20 Newsgroups):\")\n",
    "print(f\"Accuracy: {acc_c:.4f}\")\n",
    "print(classification_report(y_test_t, y_pred_c, target_names=newsgroups_train.target_names))\n",
    "\n",
    "cm_c = confusion_matrix(y_test_t, y_pred_c)\n",
    "sns.heatmap(cm_c, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (ComplementNB)')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 使用合成資料 (Binary Classification) + GridSearchCV\n",
    "\n",
    "示範對 MultinomialNB 使用 GridSearchCV 尋找最佳 alpha (平滑參數)。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_bin, y_bin = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# MultinomialNB要求非負值特徵，將特徵轉為正值\n",
    "X_train_b_pos = np.abs(X_train_b) + 1\n",
    "X_test_b_pos = np.abs(X_test_b) + 1\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "mnb_gs = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "mnb_gs.fit(X_train_b_pos, y_train_b)\n",
    "print(\"最佳參數:\", mnb_gs.best_params_)\n",
    "y_pred_gs = mnb_gs.predict(X_test_b_pos)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_b, y_pred_gs))"
   ],
   "execution_count": null,
   "outputs": []
  }, 
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline、Cross-Validation 示例\n",
    "\n",
    "以 GaussianNB 為例，進行 Cross-Validation 評估："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_iris_all = iris.data\n",
    "y_iris_all = iris.target\n",
    "\n",
    "pipe_gnb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipe_gnb, X_iris_all, y_iris_all, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy (GaussianNB on Iris):\", scores)\n",
    "print(\"Mean Accuracy:\", np.mean(scores))"
   ],
   "execution_count": null,
   "outputs": []
  },   
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 實務建議與總結\n",
    "\n",
    "### 8.1 模型選擇\n",
    "- GaussianNB：連續特徵，特徵分佈近似高斯\n",
    "- MultinomialNB：文本分類（詞頻特徵），非負離散特徵\n",
    "- BernoulliNB：二元特徵，是否出現特徵\n",
    "- ComplementNB：文本分類，不平衡資料更穩定\n",
    "\n",
    "### 8.2 Zero-Frequency問題\n",
    "使用 `alpha` 進行平滑 (拉普拉斯平滑) 避免零機率問題。\n",
    "\n",
    "### 8.3 優點與缺點\n",
    "優點：\n",
    "- 計算快速、訓練與預測效率高\n",
    "- 對高維、少量資料良好\n",
    "- 易於理解與實現\n",
    "\n",
    "缺點：\n",
    "- 特徵獨立假設不常成立\n",
    "- 對複雜關係可能無法充分捕捉\n",
    "\n",
    "### 8.4 使用建議\n",
    "- 文本分類常首選 MultinomialNB 或 BernoulliNB\n",
    "- 對連續特徵建議 GaussianNB\n",
    "- 不平衡文本資料可考慮 ComplementNB\n",
    "- 使用交叉驗證、GridSearchCV 調整參數（如 alpha）\n",
    "- 搭配特徵工程(詞頻、TF-IDF、標準化)提昇效能\n",
    "\n",
    "### 參考資料\n",
    "- [Scikit-learn Documentation: Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "- [Scikit-learn Documentation: 20 Newsgroups text dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
