{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling_ML_Models.ipynb\n",
    "\n",
    "## 簡介 (Introduction)\n",
    "\n",
    "在大數據時代，單機運算不足以有效處理與訓練龐大的資料集與模型。**Apache Spark** 提供分散式計算能力，並透過 **MLlib** 提供機器學習的高階 API，在分散式環境中訓練、評估與調優 ML 模型。\n",
    "\n",
    "本 Notebook 將示範：\n",
    "- 使用 SparkSession 啟動分散式運算環境\n",
    "- 讀取與準備資料\n",
    "- 使用 Spark MLlib 建立機器學習 Pipeline（包括特徵工程與模型）\n",
    "- 在 Spark 分散式環境中訓練模型（以邏輯回歸為例）\n",
    "- 評估模型表現與交叉驗證\n",
    "- 簡要展示參數調優（如透過 CrossValidator）\n",
    "\n",
    "請確保您已安裝好 PySpark。\n",
    "若未安裝，可透過：\n",
    "```bash\n",
    "!pip install pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始化 SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Scaling_ML_Models\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料讀取與準備\n",
    "\n",
    "此範例使用 Spark 自帶的範例資料（如 `sample_libsvm_data.txt`）做為示範。此檔案是 LIBSVM 格式，已包含標籤與特徵。\n",
    "\n",
    "如需使用自己的資料，可使用 `spark.read.csv` 或其他方法讀取後自行特徵工程。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 載入 Spark 自帶範例資料\n",
    "data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "data.show(10)\n",
    "data.printSchema()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 中有 `label` 與 `features` 欄位，`features` 是一個向量欄位。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 分割訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Training Data Count:\", train_data.count())\n",
    "print(\"Test Data Count:\", test_data.count())"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 建立 ML Pipeline\n",
    "\n",
    "Spark MLlib 的 Pipeline 可以將特徵處理與模型訓練串接。\n",
    "\n",
    "此例中資料已經是 vectorized features，不需額外的特徵工程，\n",
    "我們將直接使用 LogisticRegression。若有需要特徵工程，可使用 `VectorAssembler`, `StringIndexer`, `OneHotEncoder` 等 Transformer。",
    "\n",
    "### 使用 LogisticRegression 模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 建立 Logistic Regression 實例\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "\n",
    "# Pipeline: (此處無額外前處理，直接放入模型)\n",
    "pipeline = Pipeline(stages=[lr])\n"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型訓練\n",
    "\n",
    "透過 `pipeline.fit()` 在 Spark 分散式環境中訓練模型。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = pipeline.fit(train_data)\n",
    "print(\"Model trained.\")"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型預測與評估\n",
    "\n",
    "使用訓練好的模型對測試集做預測，並計算基本的評估指標，如 Accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(10)"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 參數調優 (Parameter Tuning) 與 交叉驗證 (Cross-Validation)\n",
    "\n",
    "可使用 `CrossValidator` 搭配 ParamGridBuilder 對模型的超參數進行調整並找到最佳參數組合。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# 建立參數網格 (例如：調整 regParam )\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.001, 0.01, 0.1])\n",
    "             .addGrid(lr.maxIter, [10, 50])\n",
    "             .build())\n",
    "\n",
    "# 使用 CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3)\n",
    "\n",
    "# 執行交叉驗證\n",
    "cvModel = cv.fit(train_data)\n",
    "\n",
    "bestModel = cvModel.bestModel\n",
    "print(\"Best Model: \", bestModel.stages)\n"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在分散式環境中，交叉驗證會平行執行不同的參數組合與資料折疊，以提高搜尋效率與速度。\n",
    "\n",
    "驗證最佳模型的表現："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cv_predictions = cvModel.transform(test_data)\n",
    "cv_accuracy = evaluator.evaluate(cv_predictions)\n",
    "print(f\"CV Test Accuracy: {cv_accuracy}\")"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 結束 Spark Session\n",
    "\n",
    "在完成後呼叫 `spark.stop()` 釋放資源。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spark.stop()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "本 Notebook 展示了如何在分散式環境（透過 Spark）訓練機器學習模型，包括：\n",
    "- 使用 SparkSession 啟動叢集運算環境\n",
    "- 讀取 LIBSVM 格式資料\n",
    "- 使用 Spark ML Pipeline 建立並訓練 Logistic Regression 模型\n",
    "- 使用 DataFrame API 與 Evaluator 進行模型預測與評估\n",
    "- 利用 CrossValidator 與 ParamGridBuilder 進行參數調優與交叉驗證\n",
    "\n",
    "透過這些步驟，你可以在分散式環境中更有效率地訓練、評估並提升 ML 模型性能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
