{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Cleaning_and_Processing.ipynb\n",
    "\n",
    "在資料科學與機器學習專案中，資料前處理（Data Cleaning & Processing）是非常重要的一個步驟。在此 Notebook，我們將示範實務中常見的資料清洗與處理技巧，包括：\n",
    "\n",
    "- 缺失值 (Missing Values) 的檢測與處理\n",
    "- 異常值 (Outliers) 的檢測與處理\n",
    "- 類別特徵編碼 (Categorical Encoding)\n",
    "- 數值轉換 (Numerical Transformation) 如正規化、標準化\n",
    "\n",
    "我們將透過一個模擬的範例數據集進行示範，並以 pandas 與 scikit-learn 的相關工具為主。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件與生成範例資料\n",
    "\n",
    "我們先行載入所需套件並生成一個模擬的資料集，以便後續示範。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 為了示範，我們建構一個虛擬資料集\n",
    "np.random.seed(42)\n",
    "size = 200\n",
    "\n",
    "# 數值特徵\n",
    "age = np.random.randint(18, 70, size)  # 年齡\n",
    "income = np.random.normal(50000, 15000, size)  # 收入\n",
    "income[np.random.choice(range(size), 5)] = np.nan  # 插入缺失值\n",
    "\n",
    "# 類別特徵\n",
    "cities = np.random.choice(['NY', 'SF', 'LA', 'missing_city'], size=size, p=[0.4, 0.3, 0.29, 0.01])\n",
    "cities[np.random.choice(range(size), 3)] = np.nan  # 類別缺失值\n",
    "\n",
    "# 二元類別特徵\n",
    "gender = np.random.choice(['M', 'F'], size=size)\n",
    "gender[np.random.choice(range(size), 2)] = np.nan\n",
    "\n",
    "# 一個可能有異常值的特徵\n",
    "expenses = np.random.normal(2000, 500, size)\n",
    "# 加入一些離群點\n",
    "expenses[np.random.choice(range(size), 3)] = [100000, 50000, 99999]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'city': cities,\n",
    "    'gender': gender,\n",
    "    'expenses': expenses\n",
    "})\n",
    "\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料集已建構完畢，包含:\n",
    "- `age`: 數值特徵（整數）\n",
    "- `income`: 數值特徵（浮點數，有些缺失值）\n",
    "- `city`: 類別特徵（含缺失值與 'missing_city' 這種特殊值）\n",
    "- `gender`: 二元類別特徵（含缺失值）\n",
    "- `expenses`: 數值特徵（有明顯異常值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值處理 (Missing Values)\n",
    "\n",
    "首先，我們先檢查缺失值的存在情況，並展示不同的填補策略：\n",
    "- **檢視缺失值分佈**\n",
    "- 使用簡單統計量填補（平均值、中位數、眾數）\n",
    "- 使用 KNNImputer 之類的方法進行較智慧的插補\n",
    "- 若類別特徵中有特殊標記（如 'missing_city'），可考慮保留此類別或以眾數填補\n",
    "\n",
    "實務上並無絕對最佳方法，需根據資料特性與業務需求決定。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 檢查缺失值數量\n",
    "df.isnull().sum()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有缺失值的特徵：`income`, `city`, `gender`\n",
    "\n",
    "### 簡單填補 (SimpleImputer)\n",
    "\n",
    "對 `income`（數值）可用平均值或中位數填補；對 `gender`（類別）可用眾數填補。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 數值特徵填補: 'income' 使用中位數\n",
    "# 類別特徵填補: 'city', 'gender' 使用最常出現的值(眾數)\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# 鑑別數值與類別特徵\n",
    "numeric_cols = ['income', 'expenses', 'age']\n",
    "categorical_cols = ['city', 'gender']\n",
    "\n",
    "num_df = df[numeric_cols]\n",
    "cat_df = df[categorical_cols]\n",
    "\n",
    "num_filled = pd.DataFrame(num_imputer.fit_transform(num_df), columns=numeric_cols)\n",
    "cat_filled = pd.DataFrame(cat_imputer.fit_transform(cat_df), columns=categorical_cols)\n",
    "\n",
    "df_filled = pd.concat([df[['age']], num_filled[['income','expenses']], cat_filled], axis=1)\n",
    "df_filled.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高級填補 (KNNImputer)\n",
    "\n",
    "KNNImputer 根據最近鄰樣本的平均值（對數值特徵）來插補缺失值，可能比簡單統計更精細。\n",
    "\n",
    "範例：只對數值特徵 `income` 使用 KNNImputer。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "# 只對 income 作 KNN 填補，其餘已用簡單填補完成\n",
    "\n",
    "# 我們先對原始資料中的數值特徵（age, income, expenses）嘗試 KNNImputer\n",
    "num_df = df[['age','income','expenses']]\n",
    "num_df_imputed = pd.DataFrame(knn_imputer.fit_transform(num_df), columns=num_df.columns)\n",
    "num_df_imputed.isnull().sum()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNImputer 可用於數值特徵，若資料維度高則需考慮效能。\n",
    "\n",
    "## 異常值處理 (Outlier Detection & Handling)\n",
    "\n",
    "異常值可能來自資料錯誤錄入或真實但罕見的情境。在分析與建模前，可考慮：\n",
    "- 移除異常值\n",
    "- 使用 RobustScaler 等對異常值不敏感的轉換器\n",
    "- 使用對異常值不敏感的模型\n",
    "\n",
    "先透過視覺化方法（盒鬚圖、直方圖）檢視 `expenses` 特徵中離群點。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x=df['expenses'])\n",
    "plt.title('Expenses Boxplot')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過盒鬚圖可見，`expenses` 有幾個極端值（> 50000）。\n",
    "\n",
    "處理方法範例：\n",
    "1. 移除異常值（若比例很少且明顯錯誤）\n",
    "2. 將異常值截斷 (Winsorization)\n",
    "3. 使用 RobustScaler 對特徵進行縮放，使得離群值影響降低\n",
    "\n",
    "範例：使用 IQR（四分位距）法則移除異常值。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "q1 = df['expenses'].quantile(0.25)\n",
    "q3 = df['expenses'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5*iqr\n",
    "upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "mask = (df['expenses'] >= lower_bound) & (df['expenses'] <= upper_bound)\n",
    "df_no_outlier = df[mask]\n",
    "df_no_outlier.shape"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過該方法，我們將高於某閾值的離群值移除。\n",
    "\n",
    "## 類別特徵編碼 (Categorical Encoding)\n",
    "\n",
    "類別特徵（如 city, gender）需要轉換為數值表示才能餵入大多數機器學習模型。\n",
    "\n",
    "常用方法：\n",
    "- Label Encoding：將類別映射為整數標籤\n",
    "- One-Hot Encoding：對類別創建二元指標欄位\n",
    "- Target Encoding 等進階方法（本示範不涉）\n",
    "\n",
    "對 `city`、`gender` 使用 One-Hot Encoding："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 範例：One-Hot Encoding\n",
    "df_categorical = df_no_outlier.copy()\n",
    "\n",
    "# 確保已無缺失值 (若有缺失值需先填補)\n",
    "df_categorical['city'] = df_categorical['city'].fillna('Unknown')\n",
    "df_categorical['gender'] = df_categorical['gender'].fillna('Unknown_gender')\n",
    "\n",
    "one_hot = pd.get_dummies(df_categorical, columns=['city','gender'], drop_first=True)\n",
    "one_hot.head()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述利用 `get_dummies` 快速對類別特徵做 One-Hot。若需要在 pipeline 中使用，則可使用 `OneHotEncoder`："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 使用 sklearn OneHotEncoder 範例\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cat_features = df_no_outlier[['city','gender']].fillna('Unknown')\n",
    "encoded_array = encoder.fit_transform(cat_features)\n",
    "encoded_columns = encoder.get_feature_names_out(['city','gender'])\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns)\n",
    "encoded_df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數值特徵轉換 (Scaling & Transformation)\n",
    "\n",
    "在建模前，對數值特徵進行縮放或轉換可提高模型穩定性與訓練效率。\n",
    "\n",
    "常見方法：\n",
    "- StandardScaler：將數值特徵轉換為均值0、標準差1\n",
    "- MinMaxScaler：將數值壓縮到[0,1]\n",
    "- RobustScaler：對異常值不敏感，以中位數和IQR計算\n",
    "- PowerTransformer：應用 Box-Cox 或 Yeo-Johnson 轉換，使特徵分佈更接近常態\n",
    "\n",
    "範例：對 `income`、`expenses` 進行標準化與對數變換。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "numeric_df = df_no_outlier[['income','expenses','age']].copy()\n",
    "\n",
    "# 使用StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(numeric_df)\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=numeric_df.columns)\n",
    "scaled_df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可觀察 `scaled_df` 中各特徵均值接近0、標準差接近1。\n",
    "\n",
    "### 使用 PowerTransformer\n",
    "\n",
    "若特徵分佈偏斜可考慮 PowerTransformer（Yeo-Johnson），使數據更接近常態分佈。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "pt_values = pt.fit_transform(numeric_df)\n",
    "pt_df = pd.DataFrame(pt_values, columns=numeric_df.columns)\n",
    "pt_df.hist(bins=20, figsize=(12,4))\n",
    "plt.suptitle('Distributions after PowerTransformer')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "藉此，我們嘗試讓分佈更像常態，可能有助某些假設需要常態分佈的模型（如線性回歸）。\n",
    "\n",
    "## 整合處理流程 (Pipeline)\n",
    "\n",
    "在實務中，資料清理與特徵轉換常與模型訓練整合為一個 Pipeline，確保在訓練集與測試集上執行一致的處理步驟。\n",
    "\n",
    "例如：\n",
    "1. 對數值特徵缺失值以中位數填補\n",
    "2. 對類別特徵缺失值以最頻繁值填補\n",
    "3. 類別特徵 One-Hot 編碼\n",
    "4. 數值特徵標準化\n",
    "\n",
    "使用 `ColumnTransformer` 與 `Pipeline` 實現："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['income','expenses','age']\n",
    "categorical_features = ['city','gender']\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# 構建一個範例 pipeline（不含模型）\n",
    "preprocessed_data = preprocessor.fit_transform(df)\n",
    "preprocessed_data.shape"
   ],
   "execution_count": null,
   "outputs": []
  },  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "執行後可看到產出的特徵維度增多（因 One-Hot Encoding 擴增特徵）。\n",
    "\n",
    "有了此預處理 Pipeline，我們就能在訓練、交叉驗證與測試預測時自動化資料處理步驟。\n",
    "\n",
    "## 小結與建議\n",
    "\n",
    "本 Notebook 演示了常見的資料清理與處理技巧，包括缺失值填補、異常值檢測與處理、類別特徵編碼以及數值標準化與轉換。\n",
    "\n",
    "在真實專案中，需根據資料特性、業務需求、模型選擇靈活調整策略。例如：\n",
    "- 若缺失值有業務意義（如無測量值代表某狀態），可保留 'missing' 類別。\n",
    "- 異常值是否移除需判斷其是否為真實有意義的 outlier。\n",
    "- 類別特徵編碼方式可隨模型而定（樹模型對 One-Hot Encoding 並非一定必要）。\n",
    "- 數值縮放方法（StandardScaler、MinMaxScaler、RobustScaler）視特徵分佈而定。\n",
    "\n",
    "在後續的 `Exploratory_Data_Analysis.ipynb` 將以更深入的統計與視覺化方式探索資料分佈與特徵間關係，幫助決定進一步的特徵工程與建模策略。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data_Cleaning_and_Processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
