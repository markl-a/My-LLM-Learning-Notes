{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2906b8",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 引言\n",
    ":label:`chap_introduction`\n",
    "\n",
    "時至今日，人們常用的電腦程式幾乎都是軟體開發人員從零編寫的。\n",
    "比如，現在開發人員要編寫一個程式來管理網上商城。\n",
    "經過思考，開發人員可能提出如下一個解決方案：\n",
    "首先，用戶通過Web瀏覽器（或移動應用程式）與應用程式進行互動；\n",
    "緊接著，應用程式與資料庫引擎進行互動，以保存交易歷史記錄並追蹤每個用戶的動態；\n",
    "其中，這個應用程式的核心——「業務邏輯」，詳細說明了應用程式在各種情況下進行的操作。\n",
    "\n",
    "為了完善業務邏輯，開發人員必須細緻地考慮應用程式所有可能遇到的邊界情況，並為這些邊界情況設計合適的規則。\n",
    "當買家點擊將商品添加到購物車時，應用程式會向購物車資料庫表中添加一個條目，將該用戶ID與商品ID關聯起來。\n",
    "雖然一次編寫出完美應用程式的可能性微乎其微，但在大多數情況下，開發人員可以從上述的業務邏輯出發，編寫出符合業務邏輯的應用程式，並不斷測試直到滿足用戶的需求。\n",
    "根據業務邏輯設計自動化系統，驅動正常運行的產品和系統，是一個人類認知上的非凡壯舉。\n",
    "\n",
    "幸運的是，對日益壯大的機器學習科學家群體來說，實現很多任務的自動化並不再屈從於人類所能考慮到的邏輯。\n",
    "想像一下，假如開發人員要試圖解決以下問題之一：\n",
    "\n",
    "* 編寫一個應用程式，接受地理資訊、衛星圖像和一些歷史天氣資訊，並預測明天的天氣；\n",
    "* 編寫一個應用程式，接受自然文本表示的問題，並正確回答該問題；\n",
    "* 編寫一個應用程式，接受一張圖像，識別出該圖像所包含的人，並在每個人周圍繪製輪廓；\n",
    "* 編寫一個應用程式，向用戶推薦他們可能喜歡，但在自然瀏覽過程中不太可能遇到的產品。\n",
    "\n",
    "在這些情況下，即使是頂級程式設計師也無法提出完美的解決方案，\n",
    "原因可能各不相同。有時任務可能遵循一種隨著時間推移而變化的模式，我們需要程式來自動調整。\n",
    "有時任務內的關係可能太複雜（比如像素和抽象類別之間的關係），需要數千或數百萬次的計算。\n",
    "即使人類的眼睛能毫不費力地完成這些難以提出完美解決方案的任務，這其中的計算也超出了人類意識理解範疇。\n",
    "*機器學習*（machine learning，ML）是一類強大的可以從經驗中學習的技術。\n",
    "通常採用觀測數據或與環境互動的形式，機器學習演算法會積累更多的經驗，其性能也會逐步提高。\n",
    "相反，對於剛剛所說的電子商務平台，如果它一直執行相同的業務邏輯，無論積累多少經驗，都不會自動提高，除非開發人員認識到問題並更新軟體。\n",
    "本書將帶讀者開啟機器學習之旅，並特別關注*深度學習*（deep learning，DL）的基礎知識。\n",
    "深度學習是一套強大的技術，它可以推動電腦視覺、自然語言處理、醫療保健和基因組學等不同領域的創新。\n",
    "\n",
    "## 日常生活中的機器學習\n",
    "\n",
    "機器學習應用在日常生活中的方方面面。\n",
    "現在，假設本書的作者們一起開車去咖啡店。\n",
    "阿斯頓拿起一部iPhone，對它說道：「Hey Siri！」手機的語音識別系統就被喚醒了。\n",
    "接著，李沐對Siri說道：「去星巴克咖啡店。」語音識別系統就自動觸發語音轉文字功能，並啟動地圖應用程式，\n",
    "地圖應用程式在啟動後篩選了若干條路線，每條路線都顯示了預計的通行時間......\n",
    "由此可見，機器學習滲透在生活中的方方面面，在短短幾秒鐘的時間裡，人們與智慧型手機的日常互動就可以涉及幾種機器學習模型。\n",
    "\n",
    "現在，假如需要我們編寫程式來回應一個「喚醒詞」（比如「Alexa」「小愛同學」和「Hey Siri」）。\n",
    "我們試著用一台電腦和一個程式碼編輯器編寫程式，如 :numref:`fig_wake_word`中所示。\n",
    "問題看似很難解決：麥克風每秒鐘將收集大約44000個樣本，每個樣本都是聲波振幅的測量值。而該測量值與喚醒詞難以直接關聯。那又該如何編寫程式，令其輸入麥克風採集到的原始音訊片段，輸出$\\{\\text{是}, \\text{否}\\}$（表示該片段是否包含喚醒詞）的可靠預測呢？我們對編寫這個程式毫無頭緒，這就是需要機器學習的原因。\n",
    "\n",
    "![識別喚醒詞](../img/wake-word.svg)\n",
    ":label:`fig_wake_word`\n",
    "\n",
    "通常，即使我們不知道怎樣明確地告訴電腦如何從輸入映射到輸出，大腦仍然能夠自己執行認知功能。\n",
    "換句話說，即使我們不知道如何編寫電腦程式來識別「Alexa」這個詞，大腦自己也能夠識別它。\n",
    "有了這一能力，我們就可以收集一個包含大量音訊樣本的*資料集*（dataset），並對包含和不包含喚醒詞的樣本進行標記。\n",
    "利用機器學習演算法，我們不需要設計一個「明確地」識別喚醒詞的系統。\n",
    "相反，我們只需要定義一個靈活的程式演算法，其輸出由許多*參數*（parameter）決定，然後使用資料集來確定當下的「最佳參數集」，這些參數通過某種性能度量方式來達到完成任務的最佳性能。\n",
    "\n",
    "那麼到底什麼是參數呢？\n",
    "參數可以被看作旋鈕，旋鈕的轉動可以調整程式的行為。\n",
    "任一調整參數後的程式被稱為*模型*（model）。\n",
    "通過操作參數而生成的所有不同程式（輸入-輸出映射）的集合稱為「模型族」。\n",
    "使用資料集來選擇參數的元程式被稱為*學習演算法*（learning algorithm）。\n",
    "\n",
    "在開始用機器學習演算法解決問題之前，我們必須精確地定義問題，確定*輸入*（input）和*輸出*（output）的性質，並選擇合適的模型族。\n",
    "在本例中，模型接收一段音訊作為輸入，然後在是或否中生成一個選擇作為輸出。\n",
    "如果一切順利，經過一番訓練，模型對於「片段是否包含喚醒詞」的預測通常是正確的。\n",
    "\n",
    "現在模型每次聽到「Alexa」這個詞時都會發出「是」的聲音。\n",
    "由於這裡的喚醒詞是任意選擇的自然語言，因此我們可能需要一個足夠豐富的模型族，使模型多元化。\n",
    "比如，模型族的另一個模型只在聽到「Hey Siri」這個詞時發出「是」。\n",
    "理想情況下，同一個模型族應該適合於「Alexa」識別和「Hey Siri」識別，因為從直覺上看，它們似乎是相似的任務。\n",
    "然而，如果我們想處理完全不同的輸入或輸出，比如：從圖像映射到字幕，或從英語映射到中文，可能需要一個完全不同的模型族。\n",
    "\n",
    "但如果模型所有的按鈕（模型參數）都被隨機設置，就不太可能識別出「Alexa」「Hey Siri」或任何其他單詞。\n",
    "在機器學習中，*學習*（learning）是一個訓練模型的過程。\n",
    "通過這個過程，我們可以發現正確的參數集，從而使模型強制執行所需的行為。\n",
    "換句話說，我們用數據*訓練*（train）模型。\n",
    "如 :numref:`fig_ml_loop`所示，訓練過程通常包含如下步驟：\n",
    "\n",
    "1. 從一個隨機初始化參數的模型開始，這個模型基本沒有「智能」；\n",
    "1. 獲取一些數據樣本（例如，音訊片段以及對應的是或否標籤）；\n",
    "1. 調整參數，使模型在這些樣本中表現得更好；\n",
    "1. 重複第（2）步和第（3）步，直到模型在任務中的表現令人滿意。\n",
    "\n",
    "![一個典型的訓練過程](../img/ml-loop.svg)\n",
    ":label:`fig_ml_loop`\n",
    "\n",
    "總而言之，我們沒有編寫喚醒詞識別器，而是編寫了一個「學習」程式。\n",
    "如果我們用一個巨大的帶標籤的數據集，它很可能可以「學習」識別喚醒詞。\n",
    "這種「通過用數據集來確定程式行為」的方法可以被看作*用數據編程*（programming with data）。\n",
    "比如，我們可以通過向機器學習系統，提供許多貓和狗的圖片來設計一個「貓圖檢測器」。\n",
    "檢測器最終可以學會：如果輸入是貓的圖片就輸出一個非常大的正數，如果輸入是狗的圖片就會輸出一個非常小的負數。\n",
    "如果檢測器不確定輸入的圖片中是貓還是狗，它會輸出接近於零的數......\n",
    "這個例子僅僅是機器學習常見應用的冰山一角，\n",
    "而深度學習是機器學習的一個主要分支，本節稍後的內容將對其進行更詳細的解析。\n",
    "\n",
    "## 機器學習中的關鍵組件\n",
    "\n",
    "首先介紹一些核心組件。無論什麼類型的機器學習問題，都會遇到這些組件：\n",
    "\n",
    "1. 可以用來學習的*資料*（data）；\n",
    "1. 如何轉換資料的*模型*（model）；\n",
    "1. 一個*目標函數*（objective function），用來量化模型的有效性；\n",
    "1. 調整模型參數以優化目標函數的*演算法*（algorithm）。\n",
    "### 資料\n",
    " \n",
    "毋庸置疑，如果沒有資料，那麼資料科學毫無用武之地。\n",
    "每個資料集由一個個*樣本*（example, sample）組成，大多時候，它們遵循獨立同分佈(independently and identically distributed, i.i.d.)。\n",
    "樣本有時也叫做*資料點*（data point）或者*資料實例*（data instance），通常每個樣本由一組稱為*特徵*（features，或*協變量*（covariates））的屬性組成。\n",
    "機器學習模型會根據這些屬性進行預測。\n",
    "在上面的監督學習問題中，要預測的是一個特殊的屬性，它被稱為*標籤*（label，或*目標*（target））。\n",
    " \n",
    "當處理圖像資料時，每一張單獨的照片即為一個樣本，它的特徵由每個像素數值的有序列表表示。\n",
    "比如，$200\\times200$彩色照片由$200\\times200\\times3=120000$個數值組成，其中的\"3\"對應於每個空間位置的紅、綠、藍通道的強度。\n",
    "再比如，對於一組醫療資料，給定一組標準的特徵（如年齡、生命體徵和診斷），此資料可以用來嘗試預測患者是否會存活。\n",
    "\n",
    "當每個樣本的特徵類別數量都是相同的時候，其特徵向量是固定長度的，這個長度被稱為資料的*維數*（dimensionality）。\n",
    "固定長度的特徵向量是一個方便的屬性，它可以用來量化學習大量樣本。\n",
    "\n",
    "然而，並不是所有的資料都可以用\"固定長度\"的向量表示。\n",
    "以圖像資料為例，如果它們全部來自標準顯微鏡設備，那麼\"固定長度\"是可取的；\n",
    "但是如果圖像資料來自網際網路，它們很難具有相同的解析度或形狀。\n",
    "這時，將圖像裁剪成標準尺寸是一種方法，但這種辦法很局限，有丟失資訊的風險。\n",
    "此外，文字資料更不符合\"固定長度\"的要求。\n",
    "比如，對於亞馬遜等電子商務網站上的客戶評論，有些文字資料很簡短（比如\"好極了\"），有些則長篇大論。\n",
    "與傳統機器學習方法相比，深度學習的一個主要優勢是可以處理不同長度的資料。\n",
    "\n",
    "一般來說，擁有越多資料的時候，工作就越容易。\n",
    "更多的資料可以被用來訓練出更強大的模型，從而減少對預先設想假設的依賴。\n",
    "資料集的由小變大為現代深度學習的成功奠定基礎。\n",
    "在沒有大資料集的情況下，許多令人興奮的深度學習模型黯然失色。\n",
    "就算一些深度學習模型在小資料集上能夠工作，但其效能並不比傳統方法高。\n",
    "\n",
    "請注意，僅僅擁有海量的資料是不夠的，我們還需要正確的資料。\n",
    "如果資料中充滿了錯誤，或者如果資料的特徵不能預測任務目標，那麼模型很可能無效。\n",
    "有一句古語很好地反映了這個現象：\"輸入的是垃圾，輸出的也是垃圾。\"（\"Garbage in, garbage out.\"）\n",
    "此外，糟糕的預測性能甚至會加倍放大事態的嚴重性。\n",
    "在一些敏感應用中，如預測性監管、履歷篩選和用於貸款的風險模型，我們必須特別警惕垃圾資料帶來的後果。\n",
    "一種常見的問題來自不均衡的資料集，比如在一個有關醫療的訓練資料集中，某些人群沒有樣本表示。\n",
    "想像一下，假設我們想要訓練一個皮膚癌識別模型，但它（在訓練資料集中）從未\"見過\"黑色皮膚的人群，這個模型就會頓時束手無策。\n",
    "\n",
    "再比如，如果用\"過去的招聘決策資料\"來訓練一個篩選履歷的模型，那麼機器學習模型可能會無意中捕捉到歷史殘留的不公正，並將其自動化。\n",
    "然而，這一切都可能在不知情的情況下發生。\n",
    "因此，當資料不具有充分代表性，甚至包含了一些社會偏見時，模型就很有可能有偏見。\n",
    "### 模型\n",
    "\n",
    "大多數機器學習會涉及到資料的轉換。\n",
    "比如一個「攝取照片並預測笑臉」的系統。再比如透過攝取到的一組感測器讀數預測讀數的正常與異常程度。\n",
    "雖然簡單的模型能夠解決如上簡單的問題，但本書中關注的問題超出了經典方法的極限。\n",
    "深度學習與經典方法的區別主要在於：前者關注的功能強大的模型，這些模型由神經網路錯綜複雜的交織在一起，包含層層資料轉換，因此被稱為*深度學習*（deep learning）。\n",
    "在討論深度模型的過程中，本書也將提及一些傳統方法。\n",
    "\n",
    "\n",
    "### 目標函數\n",
    "\n",
    "前面的內容將機器學習介紹為「從經驗中學習」。\n",
    "這裡所說的「學習」，是指自主提高模型完成某些任務的效能。\n",
    "但是，什麼才算真正的提高呢？\n",
    "在機器學習中，我們需要定義模型的優劣程度的度量，這個度量在大多數情況是「可優化」的，這被稱之為*目標函數*（objective function）。\n",
    "我們通常定義一個目標函數，並希望優化它到最低點。\n",
    "因為越低越好，所以這些函數有時被稱為*損失函數*（loss function，或cost function）。\n",
    "但這只是一個慣例，我們也可以取一個新的函數，優化到它的最高點。\n",
    "這兩個函數本質上是相同的，只是翻轉一下符號。\n",
    "\n",
    "當任務在試圖預測數值時，最常見的損失函數是*平方誤差*（squared error），即預測值與實際值之差的平方。\n",
    "當試圖解決分類問題時，最常見的目標函數是最小化錯誤率，即預測與實際情況不符的樣本比例。\n",
    "有些目標函數（如平方誤差）很容易被優化，有些目標（如錯誤率）由於不可微性或其他複雜性難以直接優化。\n",
    "在這些情況下，通常會優化*替代目標*。\n",
    "\n",
    "通常，損失函數是根據模型參數定義的，並取決於資料集。\n",
    "在一個資料集上，我們可以透過最小化總損失來學習模型參數的最佳值。\n",
    "該資料集由一些為訓練而收集的樣本組成，稱為*訓練資料集*（training dataset，或稱為*訓練集*（training set））。\n",
    "然而，在訓練資料上表現良好的模型，並不一定在「新資料集」上有同樣的性能，這裡的「新資料集」通常稱為*測試資料集*（test dataset，或稱為*測試集*（test set））。\n",
    "\n",
    "綜上所述，可用資料集通常可以分成兩部分：訓練資料集用於擬合模型參數，測試資料集用於評估擬合的模型。\n",
    "然後我們觀察模型在這兩部分資料集的性能。\n",
    "「一個模型在訓練資料集上的性能」可以被想像成「一個學生在模擬考試中的分數」。\n",
    "這個分數用來為一些真正的期末考試做參考，即使成績令人鼓舞，也不能保證期末考試成功。\n",
    "換言之，測試性能可能會顯著偏離訓練性能。\n",
    "當一個模型在訓練集上表現良好，但不能推廣到測試集時，這個模型被稱為*過擬合*（overfitting）的。\n",
    "就像在現實生活中，儘管模擬考試考得很好，真正的考試不一定百發百中。\n",
    "\n",
    "\n",
    "### 優化算法\n",
    "\n",
    "當我們獲得了一些資料源及其表示、一個模型和一個合適的損失函數，接下來就需要一種算法，它能夠搜索出最佳參數，以最小化損失函數。\n",
    "深度學習中，大多流行的優化算法通常基於一種基本方法--*梯度下降*（gradient descent）。\n",
    "簡而言之，在每個步驟中，梯度下降法都會檢查每個參數，看看如果僅對該參數進行少量變動，訓練集損失會朝哪個方向移動。\n",
    "然後，它在可以減少損失的方向上優化參數。\n",
    "\n",
    "\n",
    "## 各種機器學習問題\n",
    "\n",
    "在機器學習的廣泛應用中，喚醒詞問題只是冰山一角。\n",
    "前面喚醒詞識別的例子，只是機器學習可以解決的眾多問題中的一個。\n",
    "下面將列出一些常見的機器學習問題和應用，為之後本書的討論做鋪墊。\n",
    "接下來會經常引用前面提到的概念，如資料、模型和優化算法。\n",
    "\n",
    "### 監督學習\n",
    "\n",
    "*監督學習*（supervised learning）擅長在「給定輸入特徵」的情況下預測標籤。\n",
    "每個「特徵-標籤」對都稱為一個*樣本*（example）。\n",
    "有時，即使標籤是未知的，樣本也可以指代輸入特徵。\n",
    "我們的目標是生成一個模型，能夠將任何輸入特徵映射到標籤（即預測）。\n",
    "\n",
    "舉一個具體的例子：\n",
    "假設我們需要預測患者的心臟病是否會發作，那麼觀察結果「心臟病發作」或「心臟病沒有發作」將是樣本的標籤。\n",
    "輸入特徵可能是生命體徵，如心率、舒張壓和收縮壓等。\n",
    "\n",
    "監督學習之所以能發揮作用，是因為在訓練參數時，我們為模型提供了一個資料集，其中每個樣本都有真實的標籤。\n",
    "用機率論術語來說，我們希望預測「估計給定輸入特徵的標籤」的條件機率。\n",
    "雖然監督學習只是幾大類機器學習問題之一，但是在工業中，大部分機器學習的成功應用都使用了監督學習。\n",
    "這是因為在一定程度上，許多重要的任務可以清晰地描述為，在給定一組特定的可用資料的情況下，估計未知事物的機率。比如：\n",
    "\n",
    "* 根據電腦斷層掃描（Computed Tomography，CT）腫瘤影像，預測是否為癌症；\n",
    "* 給出一個英語句子，預測正確的法語翻譯；\n",
    "* 根據本月的財務報告資料，預測下個月股票的價格；\n",
    "\n",
    "監督學習的學習過程一般可以分為三大步驟：\n",
    "\n",
    "1. 從已知大量資料樣本中隨機選取一個子集，為每個樣本獲取真實標籤。有時，這些樣本已有標籤（例如，患者是否在下一年內康復？）；有時，這些樣本可能需要被人工標記（例如，影像分類）。這些輸入和相應的標籤一起構成了訓練資料集；\n",
    "2. 選擇有監督的學習演算法，它將訓練資料集作為輸入，並輸出一個「已完成學習的模型」；\n",
    "3. 將之前沒有見過的樣本特徵放到這個「已完成學習的模型」中，使用模型的輸出作為相應標籤的預測。\n",
    "\n",
    "整個監督學習過程如 :numref:`fig_supervised_learning` 所示。\n",
    "\n",
    "![監督學習](../img/supervised-learning.svg)\n",
    ":label:`fig_supervised_learning`\n",
    "\n",
    "綜上所述，即使使用簡單的描述給定輸入特徵的預測標籤，監督學習也可以採取多種形式的模型，並且需要大量不同的建模決策，這取決於輸入和輸出的類型、大小和數量。\n",
    "例如，我們使用不同的模型來處理「任意長度的序列」或「固定長度的序列」。\n",
    "\n",
    "#### 回歸\n",
    "\n",
    "*回歸*（regression）是最簡單的監督學習任務之一。\n",
    "假設有一組房屋銷售數據表格，其中每行對應一個房子，每列對應一個相關的屬性，例如房屋的面積、臥室的數量、浴室的數量以及到鎮中心的步行距離，等等。\n",
    "每一行的屬性構成了一個房子樣本的特徵向量。\n",
    "如果一個人住在紐約或舊金山，而且他不是亞馬遜、谷歌、微軟或Facebook的執行長，那麼他家的特徵向量（房屋面積，臥室數量，浴室數量，步行距離）可能類似於：$[600, 1, 1, 60]$。\n",
    "如果一個人住在匹茲堡，這個特徵向量可能更接近$[3000, 4, 3, 10]$......\n",
    "當人們在市場上尋找新房子時，可能需要估計一棟房子的公平市場價值。\n",
    "為什麼這個任務可以歸類為回歸問題呢？本質上是輸出決定的。\n",
    "銷售價格（即標籤）是一個數值。\n",
    "當標籤取任意數值時，我們稱之為*回歸*問題，此時的目標是生成一個模型，使它的預測非常接近實際標籤值。\n",
    "\n",
    "生活中的許多問題都可歸類為回歸問題。\n",
    "比如，預測用戶對一部電影的評分可以被歸類為一個回歸問題。\n",
    "這裡有一個小插曲：在2009年，如果有人設計了一個很棒的算法來預測電影評分，那可能會贏得[100萬美元的奈飛獎](https://en.wikipedia.org/wiki/Netflix_Prize)。\n",
    "再比如，預測病人在醫院的住院時間也是一個回歸問題。\n",
    "總而言之，判斷回歸問題的一個很好的經驗法則是，任何有關「有多少」的問題很可能就是回歸問題。比如：\n",
    " \n",
    "* 這個手術需要多少小時；\n",
    "* 在未來6小時，這個鎮會有多少降雨量。\n",
    "\n",
    "即使你以前從未使用過機器學習，可能在不經意間，已經解決了一些回歸問題。\n",
    "例如，你讓人修理了排水管，承包商花了3小時清除污水管道中的污物，然後他寄給你一張350美元的帳單。\n",
    "而你的朋友雇了同一個承包商2小時，他收到了250美元的帳單。\n",
    "如果有人請你估算清理污物的費用，你可以假設承包商收取一些基本費用，然後按小時收費。\n",
    "如果這些假設成立，那麼給出這兩個數據樣本，你就已經可以確定承包商的定價結構：50美元上門服務費，另外每小時100美元。\n",
    "在不經意間，你就已經理解並應用了線性回歸算法。\n",
    "\n",
    "然而，以上假設有時並不可取。\n",
    "例如，一些差異是由於兩個特徵之外的幾個因素造成的。\n",
    "在這些情況下，我們將嘗試學習最小化「預測值和實際標籤值的差異」的模型。\n",
    "本書大部分章節將關注平方誤差損失函數的最小化。\n",
    "\n",
    "#### 分類\n",
    "\n",
    "雖然回歸模型可以很好地解決「有多少」的問題，但是很多問題並非如此。\n",
    "例如，一家銀行希望在其移動應用程式中添加支票掃描功能。\n",
    "具體地說，這款應用程式能夠自動理解從圖像中看到的文字，並將手寫字符映射到對應的已知字符之上。\n",
    "這種「哪一個」的問題叫做*分類*（classification）問題。\n",
    "*分類*問題希望模型能夠預測樣本屬於哪個*類別*（category，正式稱為*類*（class））。\n",
    "例如，手寫數字可能有10類，標籤被設置為數字0～9。\n",
    "最簡單的分類問題是只有兩類，這被稱之為*二項分類*（binomial classification）。\n",
    "例如，資料集可能由動物圖像組成，標籤可能是$\\mathrm{\\{貓, 狗\\}}$兩類。\n",
    "回歸是訓練一個回歸函數來輸出一個數值；\n",
    "分類是訓練一個分類器來輸出預測的類別。\n",
    "\n",
    "然而模型怎麼判斷得出這種「是」或「不是」的硬分類預測呢？\n",
    "我們可以試著用概率語言來理解模型。\n",
    "給定一個樣本特徵，模型為每個可能的類分配一個概率。\n",
    "比如，之前的貓狗分類例子中，分類器可能會輸出圖像是貓的概率為0.9。\n",
    "0.9這個數字表達什麼意思呢？\n",
    "可以這樣理解：分類器90%確定圖像描繪的是一隻貓。\n",
    "預測類別的概率的大小傳達了一種模型的不確定性，本書後面章節將討論其他運用不確定性概念的算法。\n",
    "\n",
    "當有兩個以上的類別時，我們把這個問題稱為*多項分類*（multiclass classification）問題。\n",
    "常見的例子包括手寫字符識別 $\\mathrm{\\{0, 1, 2, ... 9, a, b, c, ...\\}}$。\n",
    "與解決回歸問題不同，分類問題的常見損失函數被稱為*交叉熵*（cross-entropy），本書 :numref:`sec_softmax` 將詳細闡述。\n",
    "\n",
    "請注意，最常見的類別不一定是最終用於決策的類別。\n",
    "舉個例子，假設後院有一個如 :numref:`fig_death_cap` 所示的蘑菇。\n",
    "\n",
    "![死帽蕈——不能吃！！](../img/death-cap.jpg)\n",
    ":width:`200px`\n",
    ":label:`fig_death_cap`\n",
    "\n",
    "現在，我們想要訓練一個毒蘑菇檢測分類器，根據照片預測蘑菇是否有毒。\n",
    "假設這個分類器輸出 :numref:`fig_death_cap` 包含死帽蕈的概率是0.2。\n",
    "換句話說，分類器80%確定圖中的蘑菇不是死帽蕈。\n",
    "儘管如此，我們也不會吃它，因為不值得冒20%的死亡風險。\n",
    "換句話說，不確定風險的影響遠遠大於收益。\n",
    "因此，我們需要將「預期風險」作為損失函數，即需要將結果的概率乘以與之相關的收益（或傷害）。\n",
    "在這種情況下，食用蘑菇造成的損失為$0.2 \\times \\infty + 0.8 \\times 0 = \\infty$，而丟棄蘑菇的損失為$0.2 \\times 0 + 0.8 \\times 1 = 0.8$。\n",
    "事實上，謹慎是有道理的， :numref:`fig_death_cap`中的蘑菇實際上是一個死帽蕈。\n",
    "\n",
    "分類可能變得比二項分類、多項分類複雜得多。\n",
    "例如，有一些分類任務的變體可以用於尋找層次結構，層次結構假定在許多類之間存在某種關係。\n",
    "因此，並不是所有的錯誤都是均等的。\n",
    "人們寧願錯誤地分入一個相關的類別，也不願錯誤地分入一個遙遠的類別，這通常被稱為*層次分類*(hierarchical classification)。\n",
    "早期的一個例子是[卡爾·林奈](https://en.wikipedia.org/wiki/Carl_Linnaeus)，他對動物進行了層次分類。\n",
    "\n",
    "在動物分類的應用中，把一隻獅子狗誤認為雪納瑞可能不會太糟糕。\n",
    "但如果模型將獅子狗與恐龍混淆，就滑稽至極了。\n",
    "層次結構相關性可能取決於模型的使用者計劃如何使用模型。\n",
    "例如，響尾蛇和烏梢蛇血緣上可能很接近，但如果把響尾蛇誤認為是烏梢蛇可能會是致命的。\n",
    "因為響尾蛇是有毒的，而烏梢蛇是無毒的。\n",
    "\n",
    "#### 標記問題\n",
    "\n",
    "有些分類問題很適合於二項分類或多項分類。\n",
    "例如，我們可以訓練一個普通的二項分類器來區分貓和狗。\n",
    "運用最前沿的電腦視覺的算法，這個模型可以很輕鬆地被訓練。\n",
    "儘管如此，無論模型有多精確，當分類器遇到新的動物時可能會束手無策。\n",
    "比如 :numref:`fig_stackedanimals`所示的這張「不來梅的城市音樂家」的圖像（這是一個流行的德國童話故事），圖中有一隻貓、一隻公雞、一隻狗、一頭驢，背景是一些樹。\n",
    "取決於我們最終想用模型做什麼，將其視為二項分類問題可能沒有多大意義。\n",
    "取而代之，我們可能想讓模型描繪輸入圖像的內容，一隻貓、一隻公雞、一隻狗，還有一頭驢。\n",
    "\n",
    "![一隻貓、一隻公雞、一隻狗、一頭驢](../img/stackedanimals.png)\n",
    ":width:`300px`\n",
    ":label:`fig_stackedanimals`\n",
    "\n",
    "學習預測不相互排斥的類別的問題稱為*多標籤分類*（multi-label classification）。\n",
    "舉個例子，人們在技術部落格上貼的標籤，比如「機器學習」「技術」「小工具」「程式語言」「Linux」「雲端運算」「AWS」。\n",
    "一篇典型的文章可能會用5～10個標籤，因為這些概念是相互關聯的。\n",
    "關於「雲端運算」的貼文可能會提到「AWS」，而關於「機器學習」的貼文也可能涉及「程式語言」。\n",
    "\n",
    "此外，在處理生物醫學文獻時，我們也會遇到這類問題。\n",
    "正確地標記文獻很重要，有利於研究人員對文獻進行詳盡的審查。\n",
    "在美國國家醫學圖書館（The United States National Library of Medicine），一些專業的註釋員會檢查每一篇在PubMed中被索引的文章，以便將其與Mesh中的相關術語相關聯（Mesh是一個大約有28000個標籤的集合）。\n",
    "這是一個十分耗時的過程，註釋器通常在歸檔和標記之間有一年的延遲。\n",
    "這裡，機器學習算法可以提供臨時標籤，直到每一篇文章都有嚴格的人工審核。\n",
    "事實上，近幾年來，BioASQ組織已經[舉辦比賽](http://bioasq.org/)來完成這項工作。\n",
    "\n",
    "\n",
    "#### 搜尋\n",
    "\n",
    "有時，我們不僅僅希望輸出一個類別或一個實值。\n",
    "在資訊檢索領域，我們希望對一組項目進行排序。\n",
    "以網路搜尋為例，目標不是簡單的「查詢（query）-網頁（page）」分類，而是在海量搜尋結果中找到使用者最需要的那部分。\n",
    "搜尋結果的排序也十分重要，學習演算法需要輸出有序的元素子集。\n",
    "換句話說，如果要求我們輸出字母表中的前5個字母，返回「A、B、C、D、E」和「C、A、B、E、D」是不同的。\n",
    "即使結果集是相同的，集內的順序有時卻很重要。\n",
    "\n",
    "該問題的一種可能的解決方案：首先為集合中的每個元素分配相應的相關性分數，然後檢索評級最高的元素。[PageRank](https://en.wikipedia.org/wiki/PageRank)，谷歌搜尋引擎背後最初的秘密武器就是這種評分系統的早期例子，但它的奇特之處在於它不依賴於實際的查詢。\n",
    "在這裡，他們依靠一個簡單的相關性過濾來識別一組相關條目，然後根據PageRank對包含查詢條件的結果進行排序。\n",
    "如今，搜尋引擎使用機器學習和使用者行為模型來獲取網頁相關性得分，很多學術會議也致力於這一主題。\n",
    "\n",
    "\n",
    "#### 推薦系統\n",
    ":label:`subsec_recommender_systems`\n",
    "\n",
    "另一類與搜尋和排名相關的問題是*推薦系統*（recommender system），它的目標是向特定使用者進行「個性化」推薦。\n",
    "例如，對於電影推薦，科幻迷和喜劇愛好者的推薦結果頁面可能會有很大不同。\n",
    "類似的應用也會出現在零售產品、音樂和新聞推薦等等。\n",
    "\n",
    "在某些應用中，客戶會提供明確反饋，表達他們對特定產品的喜愛程度。\n",
    "例如，亞馬遜上的產品評級和評論。\n",
    "在其他一些情況下，客戶會提供隱性反饋。\n",
    "例如，某使用者跳過播放清單中的某些歌曲，這可能說明這些歌曲對此使用者不大合適。\n",
    "總的來說，推薦系統會為「給定使用者和物品」的匹配性打分，這個「分數」可能是估計的評級或購買的機率。\n",
    "由此，對於任何給定的使用者，推薦系統都可以檢索得分最高的對象集，然後將其推薦給使用者。以上只是簡單的演算法，而工業生產的推薦系統要先進得多，它會將詳細的使用者活動和項目特徵考慮在內。\n",
    "推薦系統演算法經過調整，可以捕捉一個人的偏好。\n",
    "比如， :numref:`fig_deeplearning_amazon` 是亞馬遜基於個性化演算法推薦的深度學習書籍，成功地捕捉了作者的喜好。\n",
    "\n",
    "![亞馬遜推薦的深度學習書籍](../img/deeplearning-amazon.jpg)\n",
    ":label:`fig_deeplearning_amazon`\n",
    "\n",
    "儘管推薦系統具有巨大的應用價值，但單純用它作為預測模型仍存在一些缺陷。\n",
    "首先，我們的資料只包含「審查後的反饋」：使用者更傾向於給他們感覺強烈的事物打分。\n",
    "例如，在五分制電影評分中，會有許多五星級和一星級評分，但三星級卻明顯很少。\n",
    "此外，推薦系統有可能形成反饋循環：推薦系統首先會優先推送一個購買量較大（可能被認為更好）的商品，然而目前使用者的購買習慣往往是遵循推薦演算法，但學習演算法並不總是考慮到這一細節，進而更頻繁地被推薦。\n",
    "綜上所述，關於如何處理審查、激勵和反饋循環的許多問題，都是重要的開放性研究問題。\n",
    "\n",
    "#### 序列學習\n",
    "\n",
    "以上大多數問題都具有固定大小的輸入和產生固定大小的輸出。\n",
    "例如，在預測房價的問題中，我們考慮從一組固定的特徵：房屋面積、臥室數量、浴室數量、步行到市中心的時間；\n",
    "圖像分類問題中，輸入為固定尺寸的圖像，輸出則為固定數量（有關每一個類別）的預測機率；\n",
    "在這些情況下，模型只會將輸入作為生成輸出的「原料」，而不會「記住」輸入的具體內容。\n",
    "\n",
    "如果輸入的樣本之間沒有任何關係，以上模型可能完美無缺。\n",
    "但是如果輸入是連續的，模型可能就需要擁有「記憶」功能。\n",
    "比如，我們該如何處理視頻片段呢？\n",
    "在這種情況下，每個視頻片段可能由不同數量的幀組成。\n",
    "通過前一幀的圖像，我們可能對後一幀中發生的事情更有把握。\n",
    "語言也是如此，機器翻譯的輸入和輸出都為文字序列。\n",
    "\n",
    "再比如，在醫學上序列輸入和輸出就更為重要。\n",
    "設想一下，假設一個模型被用來監控重症監護病人，如果他們在未來24小時內死亡的風險超過某個閾值，這個模型就會發出警報。\n",
    "我們絕不希望拋棄過去每小時有關病人病史的所有資訊，而僅根據最近的測量結果做出預測。\n",
    "\n",
    "這些問題是序列學習的實例，是機器學習最令人興奮的應用之一。\n",
    "序列學習需要攝取輸入序列或預測輸出序列，或兩者兼而有之。\n",
    "具體來說，輸入和輸出都是可變長度的序列，例如機器翻譯和從語音中轉錄文本。\n",
    "雖然不可能考慮所有類型的序列轉換，但以下特殊情況值得一提。\n",
    "\n",
    "**標記和解析**。這涉及到用屬性註釋文本序列。\n",
    "換句話說，輸入和輸出的數量基本上是相同的。\n",
    "例如，我們可能想知道動詞和主語在哪裡，或者可能想知道哪些單詞是命名實體。\n",
    "通常，目標是基於結構和語法假設對文本進行分解和註釋，以獲得一些註釋。\n",
    "這聽起來比實際情況要複雜得多。\n",
    "下面是一個非常簡單的示例，它使用「標記」來註釋一個句子，該標記指示哪些單詞引用命名實體。\n",
    "標記為「Ent」，是*實體*（entity）的簡寫。\n",
    "\n",
    "```text\n",
    "Tom has dinner in Washington with Sally\n",
    "Ent  -    -    -     Ent      -    Ent\n",
    "```\n",
    "\n",
    "**自動語音識別**。在語音識別中，輸入序列是說話人的錄音（如 :numref:`fig_speech` 所示），輸出序列是說話人所說內容的文本記錄。\n",
    "它的挑戰在於，與文本相比，音頻幀多得多（聲音通常以8kHz或16kHz採樣）。\n",
    "也就是說，音頻和文本之間沒有1:1的對應關係，因為數千個樣本可能對應於一個單獨的單詞。\n",
    "這也是「序列到序列」的學習問題，其中輸出比輸入短得多。\n",
    "\n",
    "![`-D-e-e-p- L-ea-r-ni-ng-` 在錄音中。](../img/speech.png)\n",
    ":width:`700px`\n",
    ":label:`fig_speech`\n",
    "\n",
    "**文本到語音**。這與自動語音識別相反。\n",
    "換句話說，輸入是文本，輸出是音頻文件。\n",
    "在這種情況下，輸出比輸入長得多。\n",
    "雖然人類很容易識判斷發音彆扭的音頻文件，但這對電腦來說並不是那麼簡單。\n",
    "**機器翻譯**。\n",
    "在語音識別中，輸入和輸出的出現順序基本相同。\n",
    "而在機器翻譯中，顛倒輸入和輸出的順序非常重要。\n",
    "換句話說，雖然我們仍將一個序列轉換成另一個序列，但是輸入和輸出的數量以及相應序列的順序大都不會相同。\n",
    "比如下面這個例子，「錯誤的對齊」反應了德國人喜歡把動詞放在句尾的特殊傾向。\n",
    "\n",
    "```text\n",
    "德語:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?\n",
    "英語:          Did you already check out this excellent tutorial?\n",
    "錯誤的對齊:  Did you yourself already this excellent tutorial looked-at?\n",
    "```\n",
    "\n",
    "其他學習任務也有序列學習的應用。\n",
    "例如，確定「用戶閱讀網頁的順序」是二維布局分析問題。\n",
    "再比如，對話問題對序列的學習更為複雜：確定下一輪對話，需要考慮對話歷史狀態以及現實世界的知識......\n",
    "如上這些都是熱門的序列學習研究領域。\n",
    "\n",
    "\n",
    "### 無監督學習\n",
    "\n",
    "到目前為止，所有的例子都與監督學習有關，即需要向模型提供巨大數據集：每個樣本包含特徵和相應標籤值。\n",
    "打趣一下，\"監督學習\"模型像一個打工仔，有一份極其專業的工作和一位極其平庸的老闆。\n",
    "老闆站在身後，準確地告訴模型在每種情況下應該做什麼，直到模型學會從情況到行動的映射。\n",
    "取悅這位老闆很容易，只需儘快識別出模式並模仿他們的行為即可。\n",
    "\n",
    "相反，如果工作沒有十分具體的目標，就需要\"自發\"地去學習了。\n",
    "比如，老闆可能會給我們一大堆數據，然後要求用它做一些數據科學研究，卻沒有對結果有要求。\n",
    "這類數據中不含有\"目標\"的機器學習問題通常被為*無監督學習*（unsupervised learning），\n",
    "本書後面的章節將討論無監督學習技術。\n",
    "那麼無監督學習可以回答什麼樣的問題呢？來看看下面的例子。\n",
    "\n",
    "* *聚類*（clustering）問題：沒有標籤的情況下，我們是否能給數據分類呢？比如，給定一組照片，我們能把它們分成風景照片、狗、嬰兒、貓和山峰的照片嗎？同樣，給定一組用戶的網頁瀏覽記錄，我們能否將具有相似行為的用戶聚類呢？\n",
    "* *主成分分析*（principal component analysis）問題：我們能否找到少量的參數來準確地捕捉數據的線性相關屬性？比如，一個球的運動軌跡可以用球的速度、直徑和質量來描述。再比如，裁縫們已經開發出了一小部分參數，這些參數相當準確地描述了人體的形狀，以適應衣服的需要。另一個例子：在歐幾里得空間中是否存在一種（任意結構的）對象的表示，使其符號屬性能夠很好地匹配？這可以用來描述實體及其關係，例如\"羅馬\" $-$ \"意大利\" $+$ \"法國\" $=$ \"巴黎\"。\n",
    "* *因果關係*（causality）和*概率圖模型*（probabilistic graphical models）問題：我們能否描述觀察到的許多數據的根本原因？例如，如果我們有關於房價、污染、犯罪、地理位置、教育和工資的人口統計數據，我們能否簡單地根據經驗數據發現它們之間的關係？\n",
    "* *生成對抗性網絡*（generative adversarial networks）：為我們提供一種合成數據的方法，甚至像圖像和音頻這樣複雜的非結構化數據。潛在的統計機制是檢查真實和虛假數據是否相同的測試，它是無監督學習的另一個重要而令人興奮的領域。\n",
    "\n",
    "\n",
    "### 與環境互動\n",
    "\n",
    "有人一直心存疑慮：機器學習的輸入（數據）來自哪裡？機器學習的輸出又將去往何方？\n",
    "到目前為止，不管是監督學習還是無監督學習，我們都會預先獲取大量數據，然後啟動模型，不再與環境互動。\n",
    "這裡所有學習都是在算法與環境斷開後進行的，被稱為*離線學習*（offline learning）。\n",
    "對於監督學習，從環境中收集數據的過程類似於 :numref:`fig_data_collection`。\n",
    "\n",
    "![從環境中為監督學習收集數據。](../img/data-collection.svg)\n",
    ":label:`fig_data_collection`\n",
    "\n",
    "這種簡單的離線學習有它的魅力。\n",
    "好的一面是，我們可以孤立地進行模式識別，而不必分心於其他問題。\n",
    "但缺點是，解決的問題相當有限。\n",
    "這時我們可能會期望人工智能不僅能夠做出預測，而且能夠與真實環境互動。\n",
    "與預測不同，\"與真實環境互動\"實際上會影響環境。\n",
    "這裡的人工智能是\"智能代理\"，而不僅是\"預測模型\"。\n",
    "因此，我們必須考慮到它的行為可能會影響未來的觀察結果。\n",
    "\n",
    "考慮\"與真實環境互動\"將打開一整套新的建模問題。以下只是幾個例子。\n",
    "\n",
    "* 環境還記得我們以前做過什麼嗎？\n",
    "* 環境是否有助於我們建模？例如，用戶將文本讀入語音識別器。\n",
    "* 環境是否想要打敗模型？例如，一個對抗性的設置，如垃圾郵件過濾或玩遊戲？\n",
    "* 環境是否重要？\n",
    "* 環境是否變化？例如，未來的數據是否總是與過去相似，還是隨著時間的推移會發生變化？是自然變化還是響應我們的自動化工具而發生變化？\n",
    "\n",
    "當訓練和測試數據不同時，最後一個問題提出了*分布偏移*（distribution shift）的問題。\n",
    "接下來的內容將簡要描述強化學習問題，這是一類明確考慮與環境交互的問題。\n",
    "\n",
    "\n",
    "### 強化學習\n",
    "\n",
    "如果你對使用機器學習開發與環境交互並採取行動感興趣，那麼最終可能會專注於*強化學習*（reinforcement learning）。\n",
    "這可能包括應用到機器人、對話系統，甚至開發視頻遊戲的人工智能（AI）。\n",
    "*深度強化學習*（deep reinforcement learning）將深度學習應用於強化學習的問題，是非常熱門的研究領域。\n",
    "突破性的深度*Q網絡*（Q-network）在雅達利遊戲中僅使用視覺輸入就擊敗了人類，\n",
    "以及 AlphaGo 程序在棋盤遊戲圍棋中擊敗了世界冠軍，是兩個突出強化學習的例子。\n",
    "\n",
    "在強化學習問題中，智能體（agent）在一系列的時間步驟上與環境交互。\n",
    "在每個特定時間點，智能體從環境接收一些*觀察*（observation），並且必須選擇一個*動作*（action），然後通過某種機制（有時稱為執行器）將其傳輸回環境，最後智能體從環境中獲得*獎勵*（reward）。\n",
    "此後新一輪循環開始，智能體接收後續觀察，並選擇後續操作，依此類推。\n",
    "強化學習的過程在 :numref:`fig_rl-environment` 中進行了說明。\n",
    "請注意，強化學習的目標是產生一個好的*策略*（policy）。\n",
    "強化學習智能體選擇的\"動作\"受策略控制，即一個從環境觀察映射到行動的功能。\n",
    "\n",
    "![強化學習和環境之間的相互作用](../img/rl-environment.svg)\n",
    ":label:`fig_rl-environment`\n",
    "\n",
    "強化學習框架的通用性十分強大。\n",
    "例如，我們可以將任何監督學習問題轉化為強化學習問題。\n",
    "假設我們有一個分類問題，可以創建一個強化學習智能體，每個分類對應一個\"動作\"。\n",
    "然後，我們可以創建一個環境，該環境給予智能體的獎勵。\n",
    "這個獎勵與原始監督學習問題的損失函數是一致的。\n",
    "\n",
    "當然，強化學習還可以解決許多監督學習無法解決的問題。\n",
    "例如，在監督學習中，我們總是希望輸入與正確的標籤相關聯。\n",
    "但在強化學習中，我們並不假設環境告訴智能體每個觀測的最優動作。\n",
    "一般來說，智能體只是得到一些獎勵。\n",
    "此外，環境甚至可能不會告訴是哪些行為導致了獎勵。\n",
    "\n",
    "以強化學習在國際象棋的應用為例。\n",
    "唯一真正的獎勵信號出現在遊戲結束時：當智能體獲勝時，智能體可以得到獎勵1；當智能體失敗時，智能體將得到獎勵-1。\n",
    "因此，強化學習者必須處理*學分分配*（credit assignment）問題：決定哪些行為是值得獎勵的，哪些行為是需要懲罰的。\n",
    "就像一個員工升職一樣，這次升職很可能反映了前一年的大量的行動。\n",
    "要想在未來獲得更多的晉升，就需要弄清楚這一過程中哪些行為導致了晉升。\n",
    "\n",
    "強化學習可能還必須處理部分可觀測性問題。\n",
    "也就是說，當前的觀察結果可能無法闡述有關當前狀態的所有信息。\n",
    "比方說，一個清潔機器人發現自己被困在一個許多相同的壁櫥的房子裡。\n",
    "推斷機器人的精確位置（從而推斷其狀態），需要在進入壁櫥之前考慮它之前的觀察結果。\n",
    "\n",
    "最後，在任何時間點上，強化學習智能體可能知道一個好的策略，但可能有許多更好的策略從未嘗試過的。\n",
    "強化學習智能體必須不斷地做出選擇：是應該利用當前最好的策略，還是探索新的策略空間（放棄一些短期回報來換取知識）。\n",
    "\n",
    "一般的強化學習問題是一個非常普遍的問題。\n",
    "智能體的動作會影響後續的觀察，而獎勵只與所選的動作相對應。\n",
    "環境可以是完整觀察到的，也可以是部分觀察到的，解釋所有這些複雜性可能會對研究人員要求太高。\n",
    "此外，並不是每個實際問題都表現出所有這些複雜性。\n",
    "因此，學者們研究了一些特殊情況下的強化學習問題。\n",
    "\n",
    "當環境可被完全觀察到時，強化學習問題被稱為*馬爾可夫決策過程*（markov decision process）。\n",
    "當狀態不依賴於之前的操作時，我們稱該問題為*上下文賭博機*（contextual bandit problem）。\n",
    "當沒有狀態，只有一組最初未知回報的可用動作時，這個問題就是經典的*多臂賭博機*（multi-armed bandit problem）。\n",
    "\n",
    "\n",
    "## 起源\n",
    " \n",
    "為了解決各種各樣的機器學習問題，深度學習提供了強大的工具。\n",
    "雖然許多深度學習方法都是最近才有重大突破，但使用數據和神經網絡編程的核心思想已經研究了幾個世紀。\n",
    "事實上，人類長期以來就有分析數據和預測未來結果的願望，而自然科學大部分都植根於此。\n",
    "例如，伯努利分佈是以[雅各布•伯努利（1654-1705）](https://en.wikipedia.org/wiki/Jacob\\uBernoulli)命名的。\n",
    "而高斯分佈是由[卡爾•弗里德里希•高斯（1777-1855）](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss)發現的，\n",
    "他發明了最小均方算法，至今仍用於解決從保險計算到醫療診斷的許多問題。\n",
    "這些工具算法催生了自然科學中的一種實驗方法——例如，電阻中電流和電壓的歐姆定律可以用線性模型完美地描述。\n",
    " \n",
    "即使在中世紀，數學家對*估計*（estimation）也有敏銳的直覺。\n",
    "例如，[雅各布·克貝爾 (1460--1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry)的幾何學書籍舉例說明，通過平均16名成年男性的腳的長度，可以得出一英尺的長度。\n",
    " \n",
    "![估計一英尺的長度](../img/koebel.jpg)\n",
    ":width:`500px`\n",
    ":label:`fig_koebel`\n",
    " \n",
    ":numref:`fig_koebel` 說明了這個估計器是如何工作的。\n",
    "16名成年男子被要求腳連腳排成一行。\n",
    "然後將它們的總長度除以16，得到現在等於1英尺的估計值。\n",
    "這個算法後來被改進以處理畸形的腳——將擁有最短和最長腳的兩個人送走，對其餘的人取平均值。\n",
    "這是最早的修剪均值估計的例子之一。\n",
    "\n",
    "隨著數據的收集和可獲得性，統計數據真正實現了騰飛。\n",
    "[羅納德·費舍爾（1890-1962）](https://en.wikipedia.org/wiki/Ronald_-Fisher)對統計理論和在遺傳學中的應用做出了重大貢獻。\n",
    "他的許多算法（如線性判別分析）和公式（如費舍爾信息矩陣）至今仍被頻繁使用。\n",
    "甚至，費舍爾在1936年發布的鳶尾花卉數據集，有時仍然被用來解讀機器學習算法。\n",
    "他也是優生學的倡導者，這提醒我們：數據科學在道德上存疑的使用，與其在工業和自然科學中的生產性使用一樣，有著悠遠而持久的歷史。\n",
    " \n",
    "機器學習的第二個影響來自[克勞德·香農(1916--2001)](https://en.wikipedia.org/wiki/Claude_Shannon)的信息論和[艾倫·圖靈（1912-1954）](https://en.wikipedia.org/wiki/Alan_Turing)的計算理論。\n",
    "圖靈在他著名的論文《計算機器與智能》 :cite:`Turing.1950` 中提出了\"機器能思考嗎？\"的問題。\n",
    "在他所描述的圖靈測試中，如果人類評估者很難根據文本互動區分機器和人類的回答，那麼機器就可以被認為是\"智能的\"。\n",
    " \n",
    "另一個影響可以在神經科學和心理學中找到。\n",
    "其中，最古老的算法之一是[唐納德·赫布 (1904--1985)](https://en.wikipedia.org/wiki/Donald_O._Hebb)開創性的著作《行為的組織》 :cite:`Hebb.Hebb.1949` 。\n",
    "他提出神經元通過積極強化學習，是Rosenblatt感知器學習算法的原型，被稱為\"赫布學習\"。\n",
    "這個算法也為當今深度學習的許多隨機梯度下降算法奠定了基礎：強化期望行為和減少不良行為，從而在神經網絡中獲得良好的參數設置。\n",
    "\n",
    "*神經網絡*（neural networks）的得名源於生物靈感。\n",
    "一個多世紀以來（追溯到1873年亞歷山大·貝恩和1890年詹姆斯·謝靈頓的模型），研究人員一直試圖組裝類似於相互作用的神經元網絡的計算電路。\n",
    "隨著時間的推移，對生物學的解釋變得不再膚淺，但這個名字仍然存在。\n",
    "其核心是當今大多數網絡中都可以找到的幾個關鍵原則：\n",
    "\n",
    "* 線性和非線性處理單元的交替，通常稱為*層*（layers）；\n",
    "* 使用鏈式規則（也稱為*反向傳播*（backpropagation））一次性調整網絡中的全部參數。\n",
    " \n",
    "經過最初的快速發展，神經網絡的研究從1995年左右開始停滯不前，直到2005年才稍有起色。\n",
    "這主要是因為兩個原因。\n",
    "首先，訓練網絡（在計算上）非常昂貴。\n",
    "在上個世紀末，隨機存取存儲器（RAM）非常強大，而計算能力卻很弱。\n",
    "其次，數據集相對較小。\n",
    "事實上，費舍爾1932年的鳶尾花卉數據集是測試算法有效性的流行工具，\n",
    "而MNIST數據集的60000個手寫數字的數據集被認為是巨大的。\n",
    "考慮到數據和計算的稀缺性，*核方法*（kernel method）、*決策樹*（decision tree）和*圖模型*（graph models）等強大的統計工具（在經驗上）證明是更為優越的。\n",
    "與神經網絡不同的是，這些算法不需要數週的訓練，而且有很強的理論依據，可以提供可預測的結果。\n",
    "\n",
    "## 深度學習的發展\n",
    "\n",
    "大約2010年開始，那些在計算上看起來不可行的神經網絡算法變得熱門起來，實際上是以下兩點導致的：\n",
    "其一，隨著互聯網的公司的出現，為數億在線用戶提供服務，大規模數據集變得觸手可及；\n",
    "另外，廉價又高質量的傳感器、廉價的數據存儲（克萊德定律）以及廉價計算（摩爾定律）的普及，特別是GPU的普及，使大規模算力唾手可得。\n",
    " \n",
    "這一點在 :numref:`tab_intro_decade` 中得到了說明。\n",
    "\n",
    ":數據集vs計算機內存和計算能力\n",
    "\n",
    "| 年代 | 數據規模              | 內存   | 每秒浮點運算        |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| 1970 | 100 （鳶尾花卉）      | 1 KB   | 100 KF (Intel 8080) |\n",
    "| 1980 | 1 K （波士頓房價）    | 100 KB | 1 MF (Intel 80186)  |\n",
    "| 1990 | 10 K （光學字符識別） | 10 MB  | 10 MF (Intel 80486) |\n",
    "| 2000 | 10 M （網頁）         | 100 MB | 1 GF (Intel Core)   |\n",
    "| 2010 | 10 G （廣告）         | 1 GB   | 1 TF (Nvidia C2050) |\n",
    "| 2020 | 1 T （社交網絡）      | 100 GB | 1 PF (Nvidia DGX-2) |\n",
    ":label:`tab_intro_decade`\n",
    "\n",
    "很明顯，隨機存取存儲器沒有跟上數據增長的步伐。\n",
    "與此同時，算力的增長速度已經超過了現有數據的增長速度。\n",
    "這意味著統計模型需要提高內存效率（這通常是通過添加非線性來實現的），同時由於計算預算的增加，能夠花費更多時間來優化這些參數。\n",
    "因此，機器學習和統計的關注點從（廣義的）線性模型和核方法轉移到了深度神經網絡。\n",
    "這也造就了許多深度學習的中流砥柱，如多層感知機 :cite:`McCulloch.Pitts.1943` 、卷積神經網絡 :cite:`LeCun.Bottou.Bengio.ea.1998` 、長短期記憶網絡 :cite:`Graves.Schmidhuber.2005` 和Q學習 :cite:`Watkins.Dayan.1992` ，在相對休眠了相當長一段時間之後，在過去十年中被\"重新發現\"。\n",
    "\n",
    "最近十年，在統計模型、應用和算法方面的進展就像寒武紀大爆發——歷史上物種飛速進化的時期。\n",
    "事實上，最先進的技術不僅僅是將可用資源應用於幾十年前的算法的結果。\n",
    "下面列舉了幫助研究人員在過去十年中取得巨大進步的想法（雖然只觸及了皮毛）。\n",
    "\n",
    "\n",
    "* 新的容量控制方法，如*dropout* :cite:`Srivastava.Hinton.Krizhevsky.ea.2014`，有助於減輕過擬合的危險。這是通過在整個神經網絡中應用噪聲注入 :cite:`Bishop.1995` 來實現的，出於訓練目的，用隨機變量來代替權重。\n",
    "* 注意力機制解決了困擾統計學一個多世紀的問題：如何在不增加可學習參數的情況下增加系統的記憶和複雜性。研究人員通過使用只能被視為可學習的指針結構 :cite:`Bahdanau.Cho.Bengio.2014` 找到了一個優雅的解決方案。不需要記住整個文本序列（例如用於固定維度表示中的機器翻譯），所有需要存儲的都是指向翻譯過程的中間狀態的指針。這大大提高了長序列的準確性，因為模型在開始生成新序列之前不再需要記住整個序列。\n",
    "* 多階段設計。例如，存儲器網絡 :cite:`Sukhbaatar.Weston.Fergus.ea.2015` 和神經編程器-解釋器 :cite:`Reed.De-Freitas.2015`。它們允許統計建模者描述用於推理的迭代方法。這些工具允許重複修改深度神經網絡的內部狀態，從而執行推理鏈中的後續步驟，類似於處理器如何修改用於計算的存儲器。\n",
    "* 另一個關鍵的發展是生成對抗網絡 :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014` 的發明。傳統模型中，密度估計和生成模型的統計方法側重於找到合適的概率分佈（通常是近似的）和抽樣算法。因此，這些算法在很大程度上受到統計模型固有靈活性的限制。生成式對抗性網絡的關鍵創新是用具有可微參數的任意算法代替採樣器。然後對這些數據進行調整，使得鑑別器（實際上是一個雙樣本測試）不能區分假數據和真實數據。通過使用任意算法生成數據的能力，它為各種技術打開了密度估計的大門。馳騁的斑馬 :cite:`Zhu.Park.Isola.ea.2017` 和假名人臉 :cite:`Karras.Aila.Laine.ea.2017` 的例子都證明了這一進展。即使是業餘的塗鴉者也可以根據描述場景布局的草圖生成照片級真實圖像（ :cite:`Park.Liu.Wang.ea.2019` ）。\n",
    "* 在許多情況下，單個GPU不足以處理可用於訓練的大量數據。在過去的十年中，構建並行和分佈式訓練算法的能力有了顯著提高。設計可伸縮算法的關鍵挑戰之一是深度學習優化的主力——隨機梯度下降，它依賴於相對較小的小批量數據來處理。同時，小批量限制了GPU的效率。因此，在1024個GPU上進行訓練，例如每批32個圖像的小批量大小相當於總計約32000個圖像的小批量。最近的工作，首先是由 :cite:`Li.2017` 完成的，隨後是 :cite:`You.Gitman.Ginsburg.2017` 和 :cite:`Jia.Song.He.ea.2018` ，將觀察大小提高到64000個，將ResNet-50模型在ImageNet數據集上的訓練時間減少到不到7分鐘。作為比較——最初的訓練時間是按天為單位的。\n",
    "* 並行計算的能力也對強化學習的進步做出了相當關鍵的貢獻。這導致了計算機在圍棋、雅達利遊戲、星際爭霸和物理模擬（例如，使用MuJoCo）中實現超人性能的重大進步。有關如何在AlphaGo中實現這一點的說明，請參見如 :cite:`Silver.Huang.Maddison.ea.2016` 。簡而言之，如果有大量的（狀態、動作、獎勵）三元組可用，即只要有可能嘗試很多東西來了解它們之間的關係，強化學習就會發揮最好的作用。仿真提供了這樣一條途徑。\n",
    "* 深度學習框架在傳播思想方面發揮了至關重要的作用。允許輕鬆建模的第一代框架包括[Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch)和[Theano](https://github.com/Theano/Theano)。許多開創性的論文都是用這些工具寫的。到目前為止，它們已經被[TensorFlow](https://github.com/tensorflow/tensorflow)（通常通過其高級API [Keras](https://github.com/keras-team/keras)使用）、[CNTK](https://github.com/Microsoft/CNTK)、[Caffe 2](https://github.com/caffe2/caffe2)和[Apache MXNet](https://github.com/apache/incubator-mxnet)所取代。第三代工具，即用於深度學習的命令式工具，可以說是由[Chainer](https://github.com/chainer/chainer)率先推出的，它使用類似於Python NumPy的語法來描述模型。這個想法被[PyTorch](https://github.com/pytorch/pytorch)、MXNet的[Gluon API](https://github.com/apache/incubator-mxnet)和[Jax](https://github.com/google/jax)都採納了。\n",
    "\n",
    "\"系統研究人員構建更好的工具\"和\"統計建模人員構建更好的神經網絡\"之間的分工大大簡化了工作。\n",
    "例如，在2014年，對卡內基梅隆大學機器學習博士生來說，訓練線性回歸模型曾經是一個不容易的作業問題。\n",
    "而現在，這項任務只需不到10行代碼就能完成，這讓每個程序員輕易掌握了它。\n",
    "\n",
    "\n",
    "## 深度學習的成功案例\n",
    "\n",
    "人工智慧在交付結果方面有著悠久的歷史，它能帶來用其他方法很難實現的結果。例如，使用光學字符識別的郵件分揀系統從20世紀90年代開始部署，畢竟，這是著名的手寫數字MNIST數據集的來源。這同樣適用於閱讀銀行存款支票和對申請者的信用進行評分。系統會自動檢查金融交易是否存在欺詐。這成為許多電子商務支付系統的支柱，如PayPal、Stripe、支付寶、微信、蘋果、Visa和萬事達卡。國際象棋的電腦程序已經競爭了幾十年。機器學習在互聯網上提供搜索、推薦、個性化和排名。換句話說，機器學習是無處不在的，儘管它經常隱藏在視線之外。\n",
    " \n",
    "直到最近，人工智慧才成為人們關注的焦點，主要是因為解決了以前被認為難以解決的問題，這些問題與消費者直接相關。許多這樣的進步都歸功於深度學習。\n",
    "\n",
    "* 智能助理，如蘋果的Siri、亞馬遜的Alexa和谷歌助手，都能夠相當準確地回答口頭問題。這包括一些瑣碎的工作，比如打開電燈開關（對殘疾人來說是個福音）甚至預約理髮師和提供電話支援對話。這可能是人工智慧正在影響我們生活的最明顯的跡象。\n",
    "* 數字助理的一個關鍵要素是準確識別語音的能力。逐漸地，在某些應用中，此類系統的準確性已經提高到與人類同等水平的程度 :cite:`Xiong.Wu.Alleva.ea.2018`。\n",
    "* 物體識別同樣也取得了長足的進步。估計圖片中的物體在2010年是一項相當具有挑戰性的任務。在ImageNet基準上，來自NEC實驗室和伊利諾伊大學香檳分校的研究人員獲得了28%的Top-5錯誤率 :cite:`Lin.Lv.Zhu.ea.2010` 。到2017年，這一錯誤率降低到2.25% :cite:`Hu.Shen.Sun.2018` 。同樣，在鑑別鳥類或診斷皮膚癌方面也取得了驚人的成果。\n",
    "* 遊戲曾經是人類智慧的堡壘。從TD-Gammon開始，一個使用時差強化學習的五子棋遊戲程序，算法和計算的進步導致了算法被廣泛應用。與五子棋不同的是，國際象棋有一個複雜得多的狀態空間和一組動作。深藍公司利用大規模並行性、專用硬件和高效搜索遊戲樹 :cite:`Campbell.Hoane-Jr.Hsu.2002` 擊敗了加里·卡斯帕羅夫(Garry Kasparov)。圍棋由於其巨大的狀態空間，難度更大。AlphaGo在2015年達到了相當於人類的棋力，使用和蒙特卡洛樹抽樣  :cite:`Silver.Huang.Maddison.ea.2016` 相結合的深度學習。撲克中的挑戰是狀態空間很大，而且沒有完全觀察到（我們不知道對手的牌）。在撲克遊戲中，庫圖斯使用有效的結構化策略超過了人類的表現 :cite:`Brown.Sandholm.2017` 。這說明了遊戲取得了令人矚目的進步以及先進的算法在其中發揮了關鍵作用的事實。\n",
    "* 人工智慧進步的另一個跡象是自動駕駛汽車和卡車的出現。雖然完全自主還沒有完全觸手可及，但在這個方向上已經取得了很好的進展，特斯拉（Tesla）、英偉達（NVIDIA）和Waymo等公司的產品至少實現了部分自主。讓完全自主如此具有挑戰性的是，正確的駕駛需要感知、推理和將規則納入系統的能力。目前，深度學習主要應用於這些問題的電腦視覺方面。其餘部分則由工程師進行大量調整。\n",
    " \n",
    "同樣，上面的列表僅僅觸及了機器學習對實際應用的影響之處的皮毛。\n",
    "例如，機器人學、物流、計算生物學、粒子物理學和天文學最近取得的一些突破性進展至少部分歸功於機器學習。\n",
    "因此，機器學習正在成為工程師和科學家必備的工具。\n",
    "\n",
    "關於人工智慧的非技術性文章中，經常提到人工智慧奇點的問題：機器學習系統會變得有知覺，並獨立於主人來決定那些直接影響人類生計的事情。\n",
    "在某種程度上，人工智慧已經直接影響到人類的生計：信譽度的自動評估，車輛的自動駕駛，保釋決定的自動准予等等。\n",
    "甚至，我們可以讓Alexa打開咖啡機。\n",
    "\n",
    "幸運的是，我們離一個能夠控制人類創造者的有知覺的人工智慧系統還很遠。\n",
    "首先，人工智慧系統是以一種特定的、面向目標的方式設計、訓練和部署的。\n",
    "雖然他們的行為可能會給人一種通用智慧的錯覺，但設計的基礎是規則、啟發式和統計模型的結合。\n",
    "其次，目前還不存在能夠自我改進、自我推理、能夠在試圖解決一般任務的同時，修改、擴展和改進自己的架構的\"人工通用智慧\"工具。\n",
    " \n",
    "一個更緊迫的問題是人工智慧在日常生活中的應用。\n",
    "卡車司機和店員完成的許多瑣碎的工作很可能也將是自動化的。\n",
    "農業機器人可能會降低有機農業的成本，它們也將使收割作業自動化。\n",
    "工業革命的這一階段可能對社會的大部分地區產生深遠的影響，因為卡車司機和店員是許多國家最常見的工作之一。\n",
    "此外，如果不加注意地應用統計模型，可能會導致種族、性別或年齡偏見，如果自動驅動相應的決策，則會引起對程序公平性的合理關注。\n",
    "重要的是要確保小心使用這些算法。\n",
    "就我們今天所知，這比惡意超級智能毀滅人類的風險更令人擔憂。\n",
    "\n",
    "## 特點\n",
    "\n",
    "到目前為止，本節已經廣泛地討論了機器學習，它既是人工智慧的一個分支，也是人工智慧的一種方法。\n",
    "雖然深度學習是機器學習的一個子集，但令人眼花繚亂的算法和應用程序集讓人很難評估深度學習的具體成分是什麼。\n",
    "這就像試圖確定披薩所需的配料一樣困難，因為幾乎每種成分都是可以替代的。\n",
    "\n",
    "如前所述，機器學習可以使用數據來學習輸入和輸出之間的轉換，例如在語音識別中將音頻轉換為文本。\n",
    "在這樣做時，通常需要以適合算法的方式表示數據，以便將這種表示轉換為輸出。\n",
    "深度學習是\"深度\"的，模型學習了許多\"層\"的轉換，每一層提供一個層次的表示。\n",
    "例如，靠近輸入的層可以表示數據的低級細節，而接近分類輸出的層可以表示用於區分的更抽象的概念。\n",
    "由於*表示學習*（representation learning）目的是尋找表示本身，因此深度學習可以稱為\"多級表示學習\"。\n",
    "\n",
    "本節到目前為止討論的問題，例如從原始音頻信號中學習，圖像的原始像素值，或者任意長度的句子與外語中的對應句子之間的映射，都是深度學習優於傳統機器學習方法的問題。\n",
    "事實證明，這些多層模型能夠以以前的工具所不能的方式處理低級的感知數據。\n",
    "毋庸置疑，深度學習方法中最顯著的共同點是使用端到端訓練。\n",
    "也就是說，與其基於單獨調整的組件組裝系統，不如構建系統，然後聯合調整它們的性能。\n",
    "例如，在計算機視覺中，科學家們習慣於將特徵工程的過程與建立機器學習模型的過程分開。\n",
    "Canny邊緣檢測器 :cite:`Canny.1987` 和SIFT特徵提取器 :cite:`Lowe.2004` 作為將圖像映射到特徵向量的算法，在過去的十年裡占據了至高無上的地位。\n",
    "在過去的日子裡，將機器學習應用於這些問題的關鍵部分是提出人工設計的特徵工程方法，將數據轉換為某種適合於淺層模型的形式。\n",
    "然而，與一個算法自動執行的數百萬個選擇相比，人類通過特徵工程所能完成的事情很少。\n",
    "當深度學習開始時，這些特徵抽取器被自動調整的濾波器所取代，產生了更高的精確度。\n",
    "\n",
    "因此，深度學習的一個關鍵優勢是它不僅取代了傳統學習管道末端的淺層模型，而且還取代了勞動密集型的特徵工程過程。\n",
    "此外，通過取代大部分特定領域的預處理，深度學習消除了以前分隔計算機視覺、語音識別、自然語言處理、醫學信息學和其他應用領域的許多界限，為解決各種問題提供了一套統一的工具。\n",
    "\n",
    "除了端到端的訓練，人們正在經歷從參數統計描述到完全非參數模型的轉變。\n",
    "當數據稀缺時，人們需要依靠簡化對現實的假設來獲得有用的模型。\n",
    "當數據豐富時，可以用更準確地擬合實際情況的非參數模型來代替。\n",
    "在某種程度上，這反映了物理學在上個世紀中葉隨著計算機的出現所經歷的進步。\n",
    "現在人們可以借助於相關偏微分方程的數值模擬，而不是用手來求解電子行為的參數近似。這導致了更精確的模型，儘管常常以犧牲可解釋性為代價。\n",
    "\n",
    "與以前工作的另一個不同之處是接受次優解，處理非凸非線性優化問題，並且願意在證明之前嘗試。\n",
    "這種在處理統計問題上新發現的經驗主義，加上人才的迅速湧入，導致了實用算法的快速進步。\n",
    "儘管在許多情況下，這是以修改和重新發明存在了數十年的工具為代價的。\n",
    "\n",
    "最後，深度學習社區引以為豪的是，他們跨越學術界和企業界共享工具，發布了許多優秀的算法庫、統計模型和經過訓練的開源神經網絡。\n",
    "正是本著這種精神，本書免費分發和使用。我們努力降低每個人了解深度學習的門檻，希望讀者能從中受益。\n",
    "\n",
    "## 小結\n",
    "\n",
    "* 機器學習研究計算機系統如何利用經驗（通常是數據）來提高特定任務的性能。它結合了統計學、數據挖掘和優化的思想。通常，它是被用作實現人工智能解決方案的一種手段。\n",
    "* 表示學習作為機器學習的一類，其研究的重點是如何自動找到合適的數據表示方式。深度學習是通過學習多層次的轉換來進行的多層次的表示學習。\n",
    "* 深度學習不僅取代了傳統機器學習的淺層模型，而且取代了勞動密集型的特徵工程。\n",
    "* 最近在深度學習方面取得的許多進展，大都是由廉價傳感器和互聯網規模應用所產生的大量數據，以及（通過GPU）算力的突破來觸發的。\n",
    "* 整個系統優化是獲得高性能的關鍵環節。有效的深度學習框架的開源使得這一點的設計和實現變得非常容易。\n",
    "\n",
    "## 練習\n",
    "\n",
    "1. 你當前正在編寫的代碼的哪些部分可以\"學習\"，即通過學習和自動確定代碼中所做的設計選擇來改進？你的代碼是否包含啟發式設計選擇？\n",
    "1. 你遇到的哪些問題有許多解決它們的樣本，但沒有具體的自動化方法？這些可能是使用深度學習的主要候選者。\n",
    "1. 如果把人工智能的發展看作一場新的工業革命，那麼算法和數據之間的關係是什麼？它類似於蒸汽機和煤嗎？根本區別是什麼？\n",
    "1. 你還可以在哪裡應用端到端的訓練方法，比如 :numref:`fig_ml_loop` 、物理、工程和計量經濟學？\n",
    "\n",
    "[Discussions](https://discuss.d2l.ai/t/1744)\n",
    "\n",
    "## 練習回答\n",
    "\n",
    "1. 你當前正在編寫的代碼的哪些部分可以\"學習\"，即通過學習和自動確定代碼中所做的設計選擇來改進？你的代碼是否包含啟發式設計選擇？\n",
    "\n",
    "- 透過llm輸出特定的文本以及圖片，可以學習到如何輸出特定的文本以及圖片,並將每次輸出的狀況總結成文本提供之後llm運作相同功能時的調整,當然其中也包含許多啟發式設計選擇\n",
    "\n",
    "1. 你遇到的哪些問題有許多解決它們的樣本，但沒有具體的自動化方法？這些可能是使用深度學習的主要候選者。\n",
    "\n",
    "- 目前基本都有相關的自動化方法,不過可能可以透過llm更加優化\n",
    "\n",
    "1. 如果把人工智能的發展看作一場新的工業革命，那麼算法和數據之間的關係是什麼？它類似於蒸汽機和煤嗎？根本區別是什麼？\n",
    "\n",
    "- 演算法與數據的確像蒸汽機與煤，前者負責運作規則，後者提供驅動能量。  \n",
    "然而在 AI 世界中，演算法可無限複製、持續學習，數據也能重複利用，並非「消耗品」。  \n",
    "因此它們與工業革命的實體機械、燃料有本質上的差異。  \n",
    "\n",
    "1. 你還可以在哪裡應用端到端的訓練方法，比如 :numref:`fig_ml_loop` 、物理、工程和計量經濟學？\n",
    "\n",
    "- 端到端學習在物理、工程和計量經濟學領域應用廣泛。在**物理學**中，可用於粒子物理事件分類、訊號偵測、宇宙學參數估計等。在**工程學**裡，應用於結構健康監測、飛行器控制、機器人感知與控制等。在**計量經濟學**方面，則用於經濟預測、因果推斷和風險管理。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
