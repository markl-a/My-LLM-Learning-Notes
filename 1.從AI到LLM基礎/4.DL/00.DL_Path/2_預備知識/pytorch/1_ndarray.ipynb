{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e54cd7b",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 資料操作\n",
    ":label:`sec_ndarray`\n",
    " \n",
    "為了能夠完成各種資料操作，我們需要某種方法來儲存和操作資料。\n",
    "通常，我們需要做兩件重要的事：（1）獲取資料；（2）將資料讀入電腦後對其進行處理。\n",
    "如果沒有某種方法來儲存資料，那麼獲取資料是沒有意義的。\n",
    " \n",
    "首先，我們介紹$n$維陣列，也稱為*張量*（tensor）。\n",
    "使用過Python中NumPy計算套件的讀者會對本部分很熟悉。\n",
    "無論使用哪個深度學習框架，它的*張量類*（在MXNet中為`ndarray`，\n",
    "在PyTorch和TensorFlow中為`Tensor`）都與Numpy的`ndarray`類似。\n",
    "但深度學習框架又比Numpy的`ndarray`多一些重要功能：\n",
    "首先，GPU很好地支援加速計算，而NumPy僅支援CPU計算；\n",
    "其次，張量類支援自動微分。\n",
    "這些功能使得張量類更適合深度學習。\n",
    "如果沒有特殊說明，本書中所說的張量均指的是張量類的實例。\n",
    "\n",
    "## 入門\n",
    "\n",
    "本節的目標是幫助讀者了解並運行一些在閱讀本書的過程中會用到的基本數值計算工具。\n",
    "如果你很難理解一些數學概念或函式庫函數，請不要擔心。\n",
    "後面的章節將通過一些實際的例子來回顧這些內容。\n",
    "如果你已經具有相關經驗，想要深入學習數學內容，可以跳過本節。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b55fb",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "(**首先，我們導入`torch`。請注意，雖然它被稱為PyTorch，但是程式碼中使用`torch`而不是`pytorch`。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278e6d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:01.545874Z",
     "iopub.status.busy": "2023-08-18T07:05:01.545147Z",
     "iopub.status.idle": "2023-08-18T07:05:02.992816Z",
     "shell.execute_reply": "2023-08-18T07:05:02.991719Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15bff7",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "[**張量表示一個由數值組成的陣列，這個陣列可能有多個維度**]。\n",
    "具有一個軸的張量對應數學上的*向量*（vector）；\n",
    "具有兩個軸的張量對應數學上的*矩陣*（matrix）；\n",
    "具有兩個軸以上的張量沒有特殊的數學名稱。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723e844",
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "首先，我們可以使用 `arange` 建立一個行向量 `x`。這個行向量包含以0開始的前12個整數，它們預設建立為整數。也可指定建立類型為浮點數。張量中的每個值都稱為張量的 *元素*（element）。例如，張量 `x` 中有 12 個元素。除非額外指定，新的張量將儲存在記憶體中，並採用基於CPU的計算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1700627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:02.997386Z",
     "iopub.status.busy": "2023-08-18T07:05:02.996970Z",
     "iopub.status.idle": "2023-08-18T07:05:03.007632Z",
     "shell.execute_reply": "2023-08-18T07:05:03.006483Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ebb1e",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "[**可以透過張量的`shape`屬性來存取張量（沿著每個軸的長度）的*形狀***]\n",
    "(~~和張量中元素的總數~~)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86b6572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.011628Z",
     "iopub.status.busy": "2023-08-18T07:05:03.011110Z",
     "iopub.status.idle": "2023-08-18T07:05:03.017191Z",
     "shell.execute_reply": "2023-08-18T07:05:03.016193Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cabae8",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "如果只想知道張量中元素的總數，即形狀的所有元素乘積，可以檢查它的大小（size）。\n",
    "因為這裡在處理的是一個向量，所以它的`shape`與它的`size`相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b69ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.020938Z",
     "iopub.status.busy": "2023-08-18T07:05:03.020483Z",
     "iopub.status.idle": "2023-08-18T07:05:03.026998Z",
     "shell.execute_reply": "2023-08-18T07:05:03.025752Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15bcd6",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "[**要想改變一個張量的形狀而不改變元素數量和元素值，可以調用`reshape`函數。**]\n",
    "例如，可以把張量`x`從形狀為（12,）的行向量轉換為形狀為（3,4）的矩陣。\n",
    "這個新的張量包含與轉換前相同的值，但是它被看成一個3行4列的矩陣。\n",
    "要重點說明一下，雖然張量的形狀發生了改變，但其元素值並沒有變。\n",
    "注意，通過改變張量的形狀，張量的大小不會改變。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f294243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.031842Z",
     "iopub.status.busy": "2023-08-18T07:05:03.031448Z",
     "iopub.status.idle": "2023-08-18T07:05:03.039288Z",
     "shell.execute_reply": "2023-08-18T07:05:03.038227Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae533a0",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "我們不需要透過手動指定每個維度來改變形狀。\n",
    "也就是說，如果我們的目標形狀是（高度,寬度），\n",
    "那麼在知道寬度後，高度會被自動計算得出，不必我們自己做除法。\n",
    "在上面的例子中，為了獲得一個3行的矩陣，我們手動指定了它有3行和4列。\n",
    "幸運的是，我們可以透過`-1`來呼叫此自動計算出維度的功能。\n",
    "即我們可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`來取代`x.reshape(3,4)`。\n",
    "\n",
    "有時，我們希望[**使用全0、全1、其他常量，或者從特定分布中隨機採樣的數字**]來初始化矩陣。\n",
    "我們可以創建一個形狀為（2,3,4）的張量，其中所有元素都設置為0。程式碼如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23c3056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.044733Z",
     "iopub.status.busy": "2023-08-18T07:05:03.043866Z",
     "iopub.status.idle": "2023-08-18T07:05:03.052195Z",
     "shell.execute_reply": "2023-08-18T07:05:03.051146Z"
    },
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a180a12",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "同樣，我們可以創建一個形狀為`(2,3,4)`的張量，其中所有元素都設置為1。程式碼如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25981960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.057264Z",
     "iopub.status.busy": "2023-08-18T07:05:03.056578Z",
     "iopub.status.idle": "2023-08-18T07:05:03.064973Z",
     "shell.execute_reply": "2023-08-18T07:05:03.063853Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f1257",
   "metadata": {
    "origin_pos": 37
   },
   "source": [
    "有時我們想透過從某個特定的機率分布中隨機取樣來得到張量中每個元素的值。\n",
    "例如，當我們建構陣列來作為神經網路中的參數時，我們通常會隨機初始化參數的值。\n",
    "以下程式碼建立一個形狀為（3,4）的張量。\n",
    "其中的每個元素都從平均值為0、標準差為1的標準高斯分布（常態分布）中隨機取樣。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2493f09a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.069946Z",
     "iopub.status.busy": "2023-08-18T07:05:03.069231Z",
     "iopub.status.idle": "2023-08-18T07:05:03.077304Z",
     "shell.execute_reply": "2023-08-18T07:05:03.076139Z"
    },
    "origin_pos": 39,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9393, -1.4191, -1.3142,  1.2198],\n",
       "        [ 0.7113, -1.0781, -0.1366,  0.5977],\n",
       "        [-0.4874, -0.5705,  1.0437,  0.8175]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2299f0",
   "metadata": {
    "origin_pos": 42
   },
   "source": [
    "我們還可以[**透過提供包含數值的Python列表（或嵌套列表），來為所需張量中的每個元素賦予確定值**]。\n",
    "在這裡，最外層的列表對應於軸0，內層的列表對應於軸1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "708be494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.082360Z",
     "iopub.status.busy": "2023-08-18T07:05:03.081424Z",
     "iopub.status.idle": "2023-08-18T07:05:03.090148Z",
     "shell.execute_reply": "2023-08-18T07:05:03.088973Z"
    },
    "origin_pos": 44,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a2ec6",
   "metadata": {
    "origin_pos": 47
   },
   "source": [
    "## 運算子\n",
    "\n",
    "我們的興趣不僅限於讀取資料和寫入資料。\n",
    "我們想在這些資料上執行數學運算，其中最簡單且最有用的操作是*按元素*（elementwise）運算。\n",
    "它們將標準純量運算子應用於陣列的每個元素。\n",
    "對於將兩個陣列作為輸入的函數，按元素運算將二元運算子應用於兩個陣列中的每對位置對應的元素。\n",
    "我們可以基於任何從純量到純量的函數來創建按元素函數。\n",
    "\n",
    "在數學表示法中，我們將通過符號$f: \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "來表示*一元*純量運算子（只接收一個輸入）。\n",
    "這意味著該函數從任何實數（$\\mathbb{R}$）映射到另一個實數。\n",
    "同樣，我們通過符號$f: \\mathbb{R}, \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "表示*二元*純量運算子，這意味著該函數接收兩個輸入，並產生一個輸出。\n",
    "給定同一形狀的任意兩個向量$\\mathbf{u}$和$\\mathbf{v}$和二元運算子$f$，\n",
    "我們可以得到向量$\\mathbf{c} = F(\\mathbf{u},\\mathbf{v})$。\n",
    "具體計算方法是$c_i \\gets f(u_i, v_i)$，\n",
    "其中$c_i$、$u_i$和$v_i$分別是向量$\\mathbf{c}$、$\\mathbf{u}$和$\\mathbf{v}$中的元素。\n",
    "在這裡，我們通過將純量函數升級為按元素向量運算來生成向量值\n",
    "$F: \\mathbb{R}^d, \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$。\n",
    "\n",
    "對於任意具有相同形狀的張量，\n",
    "[**常見的標準算術運算子（`+`、`-`、`*`、`/`和`**`）都可以被升級為按元素運算**]。\n",
    "我們可以在同一形狀的任意兩個張量上調用按元素操作。\n",
    "在下面的例子中，我們使用逗號來表示一個具有5個元素的元組，其中每個元素都是按元素操作的結果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b28553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.095504Z",
     "iopub.status.busy": "2023-08-18T07:05:03.094688Z",
     "iopub.status.idle": "2023-08-18T07:05:03.106084Z",
     "shell.execute_reply": "2023-08-18T07:05:03.104976Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37bed5",
   "metadata": {
    "origin_pos": 52
   },
   "source": [
    "(**「按元素」方式可以應用更多的計算**)，包括像求冪這樣的一元運算子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef07c995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.110973Z",
     "iopub.status.busy": "2023-08-18T07:05:03.110221Z",
     "iopub.status.idle": "2023-08-18T07:05:03.120389Z",
     "shell.execute_reply": "2023-08-18T07:05:03.119471Z"
    },
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76ca21",
   "metadata": {
    "origin_pos": 57
   },
   "source": [
    "除了按元素計算外，我們還可以執行線性代數運算，包括向量點積和矩陣乘法。\n",
    "我們將在 :numref:`sec_linear-algebra`中解釋線性代數的重點內容。\n",
    "\n",
    "[**我們也可以把多個張量*連結*（concatenate）在一起**]，\n",
    "把它們端對端地疊起來形成一個更大的張量。\n",
    "我們只需要提供張量列表，並給出沿哪個軸連結。\n",
    "下面的例子分別演示了當我們沿行（軸-0，形狀的第一個元素）\n",
    "和按列（軸-1，形狀的第二個元素）連結兩個矩陣時，會發生什麼情況。\n",
    "我們可以看到，第一個輸出張量的軸-0長度（$6$）是兩個輸入張量軸-0長度的總和（$3 + 3$）；\n",
    "第二個輸出張量的軸-1長度（$8$）是兩個輸入張量軸-1長度的總和（$4 + 4$）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a583b891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.125263Z",
     "iopub.status.busy": "2023-08-18T07:05:03.124477Z",
     "iopub.status.idle": "2023-08-18T07:05:03.136328Z",
     "shell.execute_reply": "2023-08-18T07:05:03.135199Z"
    },
    "origin_pos": 59,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44965a95",
   "metadata": {
    "origin_pos": 62
   },
   "source": [
    "有時，我們想[**通過*邏輯運算符*構建二元張量**]。\n",
    "以`X == Y`為例：\n",
    "對於每個位置，如果`X`和`Y`在該位置相等，則新張量中相應項的值為1。\n",
    "這意味著邏輯語句`X == Y`在該位置處為真，否則該位置為0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6405ec63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.141449Z",
     "iopub.status.busy": "2023-08-18T07:05:03.140776Z",
     "iopub.status.idle": "2023-08-18T07:05:03.148692Z",
     "shell.execute_reply": "2023-08-18T07:05:03.147491Z"
    },
    "origin_pos": 63,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab6a71",
   "metadata": {
    "origin_pos": 64
   },
   "source": [
    "[**對張量中的所有元素進行求和，會產生一個單元素張量。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13cb291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.153907Z",
     "iopub.status.busy": "2023-08-18T07:05:03.152814Z",
     "iopub.status.idle": "2023-08-18T07:05:03.160277Z",
     "shell.execute_reply": "2023-08-18T07:05:03.159188Z"
    },
    "origin_pos": 65,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4420b99",
   "metadata": {
    "origin_pos": 67
   },
   "source": [
    "## 廣播機制\n",
    ":label:`subsec_broadcasting`\n",
    " \n",
    "在上面的部分中，我們看到了如何在相同形狀的兩個張量上執行按元素操作。\n",
    "在某些情況下，[**即使形狀不同，我們仍然可以通過調用\n",
    "*廣播機制*（broadcasting mechanism）來執行按元素操作**]。\n",
    "這種機制的工作方式如下：\n",
    "\n",
    "1. 通過適當複製元素來擴展一個或兩個數組，以便在轉換之後，兩個張量具有相同的形狀；\n",
    "2. 對生成的數組執行按元素操作。\n",
    "\n",
    "在大多數情況下，我們將沿著數組中長度為1的軸進行廣播，如下例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1de79a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.165305Z",
     "iopub.status.busy": "2023-08-18T07:05:03.164274Z",
     "iopub.status.idle": "2023-08-18T07:05:03.172771Z",
     "shell.execute_reply": "2023-08-18T07:05:03.171692Z"
    },
    "origin_pos": 69,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f53984",
   "metadata": {
    "origin_pos": 72
   },
   "source": [
    "由於`a`和`b`分別是$3\\times1$和$1\\times2$矩陣，如果讓它們相加，它們的形狀不匹配。\n",
    "我們將兩個矩陣*廣播*為一個更大的$3\\times2$矩陣，如下所示：矩陣`a`將複製列，\n",
    "矩陣`b`將複製行，然後再按元素相加。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d8904b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.177900Z",
     "iopub.status.busy": "2023-08-18T07:05:03.176935Z",
     "iopub.status.idle": "2023-08-18T07:05:03.184212Z",
     "shell.execute_reply": "2023-08-18T07:05:03.183156Z"
    },
    "origin_pos": 73,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b62722",
   "metadata": {
    "origin_pos": 74
   },
   "source": [
    "## 索引和切片\n",
    " \n",
    "就像在任何其他Python陣列中一樣，張量中的元素可以通過索引訪問。\n",
    "與任何Python陣列一樣：第一個元素的索引是0，最後一個元素索引是-1；\n",
    "可以指定範圍以包含第一個元素和最後一個之前的元素。\n",
    " \n",
    "如下所示，我們[**可以用`[-1]`選擇最後一個元素，可以用`[1:3]`選擇第二個和第三個元素**]：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b62b00c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.189786Z",
     "iopub.status.busy": "2023-08-18T07:05:03.188961Z",
     "iopub.status.idle": "2023-08-18T07:05:03.197712Z",
     "shell.execute_reply": "2023-08-18T07:05:03.196559Z"
    },
    "origin_pos": 75,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b18803",
   "metadata": {
    "origin_pos": 76,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**除了讀取外，我們還可以透過指定索引來將元素寫入矩陣。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a8261a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.203157Z",
     "iopub.status.busy": "2023-08-18T07:05:03.202390Z",
     "iopub.status.idle": "2023-08-18T07:05:03.210176Z",
     "shell.execute_reply": "2023-08-18T07:05:03.209097Z"
    },
    "origin_pos": 78,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec2856",
   "metadata": {
    "origin_pos": 80
   },
   "source": [
    "如果我們想[**為多個元素賦值相同的值，我們只需要索引所有元素，然後為它們賦值。**]\n",
    "例如，`[0:2, :]`訪問第1行和第2行，其中\":\"代表沿軸1（列）的所有元素。\n",
    "雖然我們討論的是矩陣的索引，但這也適用於向量和超過2個維度的張量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd48bae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.214118Z",
     "iopub.status.busy": "2023-08-18T07:05:03.213430Z",
     "iopub.status.idle": "2023-08-18T07:05:03.221215Z",
     "shell.execute_reply": "2023-08-18T07:05:03.220084Z"
    },
    "origin_pos": 81,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79660f82",
   "metadata": {
    "origin_pos": 83
   },
   "source": [
    "## 節省記憶體\n",
    " \n",
    "[**執行一些操作可能會導致為新結果分配記憶體**]。\n",
    "例如，如果我們用`Y = X + Y`，我們將取消引用`Y`指向的張量，而是指向新分配的記憶體處的張量。\n",
    "\n",
    "在下面的例子中，我們用Python的`id()`函數演示了這一點，\n",
    "它給我們提供了記憶體中引用物件的確切位址。\n",
    "執行`Y = Y + X`後，我們會發現`id(Y)`指向另一個位置。\n",
    "這是因為Python首先計算`Y + X`，為結果分配新的記憶體，然後使`Y`指向記憶體中的這個新位置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcd6d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.225106Z",
     "iopub.status.busy": "2023-08-18T07:05:03.224353Z",
     "iopub.status.idle": "2023-08-18T07:05:03.231715Z",
     "shell.execute_reply": "2023-08-18T07:05:03.230626Z"
    },
    "origin_pos": 84,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5a8e4",
   "metadata": {
    "origin_pos": 85
   },
   "source": [
    "這可能是不可取的，原因有兩個：\n",
    "\n",
    "1. 首先，我們不想總是不必要地分配記憶體。在機器學習中，我們可能有數百兆的參數，並且在一秒內多次更新所有參數。通常情況下，我們希望原地執行這些更新；\n",
    "2. 如果我們不原地更新，其他引用仍然會指向舊的記憶體位置，這樣我們的某些程式碼可能會無意中引用舊的參數。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2e97c",
   "metadata": {
    "origin_pos": 86,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "幸運的是，(**執行原地操作**)非常簡單。\n",
    "我們可以使用切片表示法將操作的結果分配給先前分配的陣列，例如`Y[:] = <expression>`。\n",
    "為了說明這一點，我們首先創建一個新的矩陣`Z`，其形狀與另一個`Y`相同，\n",
    "使用`zeros_like`來分配一個全$0$的區塊。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13b7fdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.236933Z",
     "iopub.status.busy": "2023-08-18T07:05:03.236016Z",
     "iopub.status.idle": "2023-08-18T07:05:03.243252Z",
     "shell.execute_reply": "2023-08-18T07:05:03.242153Z"
    },
    "origin_pos": 89,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 1916554384544\n",
      "id(Z): 1916554384544\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a38425",
   "metadata": {
    "origin_pos": 92,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**如果在後續計算中沒有重複使用`X`，\n",
    "我們也可以使用`X[:] = X + Y`或`X += Y`來減少操作的記憶體開銷。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a97d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.248290Z",
     "iopub.status.busy": "2023-08-18T07:05:03.247521Z",
     "iopub.status.idle": "2023-08-18T07:05:03.255046Z",
     "shell.execute_reply": "2023-08-18T07:05:03.253935Z"
    },
    "origin_pos": 94,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185bd60",
   "metadata": {
    "origin_pos": 96
   },
   "source": [
    "## 轉換為其他Python物件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871a6fa",
   "metadata": {
    "origin_pos": 98,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "將深度學習框架定義的張量[**轉換為NumPy張量（`ndarray`）**]很容易，反之也同樣容易。\n",
    "torch張量和numpy陣列將共享它們的底層記憶體，就地操作更改一個張量也會同時更改另一個張量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7386f580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.259655Z",
     "iopub.status.busy": "2023-08-18T07:05:03.259273Z",
     "iopub.status.idle": "2023-08-18T07:05:03.266501Z",
     "shell.execute_reply": "2023-08-18T07:05:03.265738Z"
    },
    "origin_pos": 100,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0ae4e",
   "metadata": {
    "origin_pos": 103
   },
   "source": [
    "要(**將大小為1的張量轉換為Python標量**)，我們可以呼叫`item`函數或Python的內建函數。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10a429bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:03.270566Z",
     "iopub.status.busy": "2023-08-18T07:05:03.270102Z",
     "iopub.status.idle": "2023-08-18T07:05:03.276982Z",
     "shell.execute_reply": "2023-08-18T07:05:03.276051Z"
    },
    "origin_pos": 105,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98db5b",
   "metadata": {
    "origin_pos": 108
   },
   "source": [
    "## 小結\n",
    " \n",
    "* 深度學習儲存和操作資料的主要介面是張量（$n$維陣列）。它提供了各種功能，包括基本數學運算、廣播、索引、切片、記憶體節省和轉換其他Python物件。\n",
    "\n",
    "## 練習\n",
    "\n",
    "1. 執行本節中的程式碼。將本節中的條件陳述式`X == Y`更改為`X < Y`或`X > Y`，然後看看你可以得到什麼樣的張量。\n",
    "1. 用其他形狀（例如三維張量）替換廣播機制中按元素操作的兩個張量。結果是否與預期相同？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ce063",
   "metadata": {
    "origin_pos": 110,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1747)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3be5e565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False,  True, False,  True],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]]),\n",
       " tensor([[ True, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]]),\n",
       " tensor([[False, False, False, False],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. 執行本節中的程式碼。將本節中的條件陳述式`X == Y`更改為`X < Y`或`X > Y`，然後看看你可以得到什麼樣的張量。\n",
    "## 練習\n",
    "import torch\n",
    "\n",
    "# Define tensors X and Y\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "# Perform comparisons\n",
    "result_eq = X == Y\n",
    "result_lt = X < Y\n",
    "result_gt = X > Y\n",
    "\n",
    "result_eq, result_lt, result_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "502d95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.,  2.,  6.,  6.]],\n",
       " \n",
       "         [[ 5.,  7.,  9., 11.]],\n",
       " \n",
       "         [[12., 12., 12., 12.]]]),\n",
       " tensor([[[ 0.,  1.,  8.,  9.]],\n",
       " \n",
       "         [[ 4., 10., 18., 28.]],\n",
       " \n",
       "         [[32., 27., 20., 11.]]]),\n",
       " tensor([[[-2.,  0., -2.,  0.]],\n",
       " \n",
       "         [[ 3.,  3.,  3.,  3.]],\n",
       " \n",
       "         [[ 4.,  6.,  8., 10.]]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 用其他形狀（例如三維張量）替換廣播機制中按元素操作的兩個張量。結果是否與預期相同？\n",
    "# Re-initialize the environment and perform the operations again\n",
    "import torch\n",
    "\n",
    "# Define three-dimensional tensors X and Y for broadcasting\n",
    "X_3d = torch.arange(12, dtype=torch.float32).reshape((3, 1, 4))\n",
    "Y_3d = torch.tensor([[[2.0, 1, 4, 3]], [[1, 2, 3, 4]], [[4, 3, 2, 1]]])\n",
    "\n",
    "# Perform operations using broadcasting\n",
    "result_add = X_3d + Y_3d\n",
    "result_mul = X_3d * Y_3d\n",
    "result_sub = X_3d - Y_3d\n",
    "\n",
    "result_add, result_mul, result_sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1aff6b",
   "metadata": {},
   "source": [
    "表明廣播機制在三維張量上正常運作，可進行加法、乘法、減法等按元素操作。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
